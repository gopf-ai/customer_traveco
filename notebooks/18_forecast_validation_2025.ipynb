{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 18: Forecast Validation - 2025 Actual vs ML vs Human\n",
    "\n",
    "This notebook validates our forecasting models against actual 2025 data (Jan-Sep).\n",
    "\n",
    "**Three Methods Compared:**\n",
    "1. **Human/Traditional**: 2024 annual total Ã· 12 (current budgeting method)\n",
    "2. **Machine/ML**: Model predictions from consolidated forecasts\n",
    "3. **Actual**: Real 2025 data (ground truth)\n",
    "\n",
    "**CRITICAL**: This is validation only - do NOT retrain models with 2025 data!\n",
    "\n",
    "**User Emphasis**: \"This will be the most crucial visualisation of the whole project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 18: Forecast Validation - 2025 Actual vs ML vs Human\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for utils\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "print('Notebook 18: Forecast Validation - 2025 Actual vs ML vs Human')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load 2025 Actual Data (Jan-Sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2025 actual data (Jan-Sep)...\n",
      "  Loading 2025 01 Jan QS Auftragsanalyse.xlsx...\n",
      "    Shape: (141699, 104)\n",
      "  Loading 2025 02 Feb QS Auftragsanalyse.xlsx...\n",
      "    Shape: (135739, 104)\n",
      "  Loading 2025 03 MÃ¤r QS Auftragsanalyse.xlsx...\n",
      "    Shape: (149431, 104)\n",
      "  Loading 2025 04 Apr QS Auftragsanalyse.xlsx...\n",
      "    Shape: (143718, 104)\n",
      "  Loading 2025 05 Mai QS Auftragsanalyse.xlsx...\n",
      "    Shape: (143614, 104)\n",
      "  Loading 2025 06 Jun QS Auftragsanalyse.xlsx...\n",
      "    Shape: (136156, 104)\n",
      "  Loading 2025 07 Jul QS Auftragsanalyse.xlsx...\n",
      "    Shape: (150103, 104)\n",
      "  Loading 2025 08 Aug QS Auftragsanalyse.xlsx...\n",
      "    Shape: (136073, 104)\n",
      "  Loading 2025 09 Sep QS Auftragsanalyse.xlsx...\n",
      "    Shape: (146849, 104)\n",
      "\n",
      "âœ“ Total 2025 data loaded: (1283382, 104)\n",
      "  Date range: 2025-01-01 00:00:00 to 2025-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load all 9 monthly files\n",
    "data_dir = Path('../data/raw/2025')\n",
    "\n",
    "monthly_files = [\n",
    "    '2025 01 Jan QS Auftragsanalyse.xlsx',\n",
    "    '2025 02 Feb QS Auftragsanalyse.xlsx',\n",
    "    '2025 03 MÃ¤r QS Auftragsanalyse.xlsx',\n",
    "    '2025 04 Apr QS Auftragsanalyse.xlsx',\n",
    "    '2025 05 Mai QS Auftragsanalyse.xlsx',\n",
    "    '2025 06 Jun QS Auftragsanalyse.xlsx',\n",
    "    '2025 07 Jul QS Auftragsanalyse.xlsx',\n",
    "    '2025 08 Aug QS Auftragsanalyse.xlsx',\n",
    "    '2025 09 Sep QS Auftragsanalyse.xlsx'\n",
    "]\n",
    "\n",
    "print('Loading 2025 actual data (Jan-Sep)...')\n",
    "dfs_2025 = []\n",
    "\n",
    "for file in monthly_files:\n",
    "    filepath = data_dir / file\n",
    "    print(f'  Loading {file}...')\n",
    "    df = pd.read_excel(filepath)\n",
    "    dfs_2025.append(df)\n",
    "    print(f'    Shape: {df.shape}')\n",
    "\n",
    "# Concatenate all months\n",
    "df_2025_raw = pd.concat(dfs_2025, ignore_index=True)\n",
    "print(f'\\nâœ“ Total 2025 data loaded: {df_2025_raw.shape}')\n",
    "print(f'  Date range: {df_2025_raw[\"Datum.Tour\"].min()} to {df_2025_raw[\"Datum.Tour\"].max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading supporting data...\n",
      "  Tours data: (134940, 25)\n",
      "  Sparten data: (384, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load tours and Sparten data\n",
    "print('Loading supporting data...')\n",
    "\n",
    "df_tours_2025 = pd.read_excel(data_dir / '2025 QS Tourenaufstellung bis Sept.xlsx')\n",
    "print(f'  Tours data: {df_tours_2025.shape}')\n",
    "\n",
    "df_sparten_2025 = pd.read_excel(data_dir / '2025 Sparten.xlsx')\n",
    "print(f'  Sparten data: {df_sparten_2025.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Process 2025 Data Through Full Pipeline\n",
    "\n",
    "Apply same processing as training data (Notebooks 02-04 logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2025 data with simplified aggregation...\n",
      "================================================================================\n",
      "1. Data Cleaning...\n",
      "  After filtering Lager orders: 1,279,181 records\n",
      "2. Adding temporal features...\n",
      "3. Identifying carrier types...\n",
      "  Carrier types identified\n",
      "4. Mapping Betriebszentralen...\n",
      "  âœ“ Mapped 12 betriebszentralen\n",
      "  BZ counts: {'B&T Landquart': 4251, 'B&T Puidoux': 21759, 'B&T Winterthur': 78445, 'BZ Herzogenbuchsee': 62805, 'BZ Intermodal / Rail': 3566, 'BZ Landquart': 155391, 'BZ Oberbipp': 341879, 'BZ Puidoux': 16933, 'BZ Sierre': 55769, 'BZ Sursee': 274739, 'BZ Winterthur': 260136, 'Unknown BZ': 3508}\n",
      "âœ“ Data processed: (1279181, 110)\n"
     ]
    }
   ],
   "source": [
    "print('Processing 2025 data with simplified aggregation...')\n",
    "print('='*80)\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "print('1. Data Cleaning...')\n",
    "df_2025 = df_2025_raw.copy()\n",
    "\n",
    "# Convert dates\n",
    "df_2025['Datum.Tour'] = pd.to_datetime(df_2025['Datum.Tour'])\n",
    "\n",
    "# Exclude Lager orders (warehouse operations) - inline filtering\n",
    "if 'Lieferart 2.0' in df_2025.columns:\n",
    "    df_2025 = df_2025[df_2025['Lieferart 2.0'] != 'Lager Auftrag']\n",
    "    print(f'  After filtering Lager orders: {df_2025.shape[0]:,} records')\n",
    "else:\n",
    "    print(f'  No Lager filtering applied (column not found)')\n",
    "\n",
    "# Step 2: Add temporal features (simplified)\n",
    "print('2. Adding temporal features...')\n",
    "df_2025['year'] = df_2025['Datum.Tour'].dt.year\n",
    "df_2025['month'] = df_2025['Datum.Tour'].dt.month\n",
    "df_2025['year_month'] = df_2025['Datum.Tour'].dt.to_period('M')\n",
    "\n",
    "# Step 3: Identify carrier type (internal vs external)\n",
    "print('3. Identifying carrier types...')\n",
    "if 'Nummer.Spedition' in df_2025.columns:\n",
    "    # Convert to numeric first, then classify\n",
    "    # Internal carriers: 1-8889, External: 9000+\n",
    "    df_2025['carrier_numeric'] = pd.to_numeric(df_2025['Nummer.Spedition'], errors='coerce')\n",
    "    df_2025['carrier_type'] = df_2025['carrier_numeric'].apply(\n",
    "        lambda x: 'internal' if pd.notna(x) and x < 9000 else 'external'\n",
    "    )\n",
    "    print(f'  Carrier types identified')\n",
    "else:\n",
    "    print(f'  Warning: Nummer.Spedition column not found')\n",
    "    df_2025['carrier_type'] = 'unknown'\n",
    "\n",
    "# Step 4: Map Betriebszentrale (dispatch centers)\n",
    "print('4. Mapping Betriebszentralen...')\n",
    "if 'Nummer.Auftraggeber' in df_2025.columns:\n",
    "    # Load betriebszentrale mapping\n",
    "    bz_mapping = pd.read_csv('../data/raw/TRAVECO_Betriebszentralen.csv')\n",
    "    # Convert both columns to Int64 to ensure matching types (FIX for merge error)\n",
    "    df_2025['Nummer.Auftraggeber'] = pd.to_numeric(df_2025['Nummer.Auftraggeber'], errors='coerce').astype('Int64')\n",
    "    bz_mapping['Nummer.Auftraggeber'] = pd.to_numeric(bz_mapping['Nummer.Auftraggeber'], errors='coerce').astype('Int64')\n",
    "    # Merge to add betriebszentrale_name\n",
    "    df_2025 = df_2025.merge(\n",
    "        bz_mapping[['Nummer.Auftraggeber', 'Name1']],\n",
    "        on='Nummer.Auftraggeber',\n",
    "        how='left'\n",
    "    )\n",
    "    df_2025.rename(columns={'Name1': 'betriebszentrale_name'}, inplace=True)\n",
    "    # Fill missing values with \"Unknown BZ\"\n",
    "    df_2025['betriebszentrale_name'].fillna('Unknown BZ', inplace=True)\n",
    "    print(f'  âœ“ Mapped {df_2025[\"betriebszentrale_name\"].nunique()} betriebszentralen')\n",
    "    print(f'  BZ counts: {dict(sorted(df_2025[\"betriebszentrale_name\"].value_counts().items()))}')\n",
    "else:\n",
    "    print('  âš ï¸ Warning: Nummer.Auftraggeber column not found')\n",
    "    df_2025['betriebszentrale_name'] = 'Unknown BZ'\n",
    "\n",
    "print(f'âœ“ Data processed: {df_2025.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 3: Monthly Aggregation (Orders & Revenue Focus)\nprint('\\n3. Monthly Aggregation (Orders & Revenue)...')\n\n# Group by year_month for aggregation\ndf_2025['year_month'] = df_2025['Datum.Tour'].dt.to_period('M')\n\n# Aggregate order-level metrics (focus on key business metrics)\ndf_2025_monthly = df_2025.groupby('year_month').agg({\n    'NummerKomplett.Auftrag': 'count',  # total_orders\n    'Distanz_BE.Auftrag': 'sum',  # total_km_billed (order-based billing KM)\n    'carrier_type': lambda x: (x == 'external').sum(),  # external_drivers count\n    'âˆ‘ Einnahmen': 'sum'  # revenue_total\n}).reset_index()\n\n# Rename columns\ndf_2025_monthly.columns = ['year_month', 'total_orders', 'total_km_billed', 'external_drivers', 'revenue_total']\n\n# Add date column\ndf_2025_monthly['date'] = df_2025_monthly['year_month'].dt.to_timestamp()\n\n# Count total drivers (unique carriers per month)\ndrivers_per_month = df_2025.groupby('year_month')['Nummer.Spedition'].nunique().reset_index()\ndrivers_per_month.columns = ['year_month', 'total_drivers']\ndf_2025_monthly = df_2025_monthly.merge(drivers_per_month, on='year_month', how='left')\n\nprint(f'  âœ“ Aggregated to monthly level: {df_2025_monthly.shape}')\nprint(f'  âœ“ Metrics: {list(df_2025_monthly.columns)}')\nprint(f'\\n  Monthly aggregated data (first 3 months):')\ndisplay_cols = ['date', 'total_orders', 'total_drivers', 'revenue_total']\ndisplay(df_2025_monthly[display_cols].head(3))\n\nprint('\\n  âš ï¸  Note: Tour-level metrics (total_km_actual, vehicle costs) not available')\nprint('      2025 tour data structure differs from 2024 (missing Nummer.Auftraggeber, IST KM PraCar)')\nprint('      Validation focuses on key business metrics: orders & revenue')\n\n# Step 4: Branch-level aggregation (keep existing)\nprint('\\n4. Branch-Level Aggregation (by Betriebszentrale)...')\n\n# Aggregate by year_month AND betriebszentrale\ndf_2025_monthly_bz = df_2025.groupby(['year_month', 'betriebszentrale_name']).agg({\n    'NummerKomplett.Auftrag': 'count',  # total_orders\n    'Distanz_BE.Auftrag': 'sum',  # total_km\n    'carrier_type': lambda x: (x == 'external').sum(),  # external_drivers count\n    'âˆ‘ Einnahmen': 'sum'  # revenue_total\n}).reset_index()\n\n# Rename columns\ndf_2025_monthly_bz.columns = ['year_month', 'betriebszentrale', 'total_orders', 'total_km', 'external_drivers', 'revenue_total']\n\n# Add date column\ndf_2025_monthly_bz['date'] = df_2025_monthly_bz['year_month'].dt.to_timestamp()\n\n# Count total drivers per branch per month\ndrivers_per_branch_month = df_2025.groupby(['year_month', 'betriebszentrale_name'])['Nummer.Spedition'].nunique().reset_index()\ndrivers_per_branch_month.columns = ['year_month', 'betriebszentrale', 'total_drivers']\ndf_2025_monthly_bz = df_2025_monthly_bz.merge(drivers_per_branch_month, on=['year_month', 'betriebszentrale'], how='left')\n\n# Save branch-level 2025 actual data for Notebook 19\ndf_2025_monthly_bz.to_csv('../data/processed/2025_actual_by_branch.csv', index=False)\n\nprint(f'  âœ“ Aggregated by branch: {df_2025_monthly_bz.shape}')\nprint(f'  âœ“ Betriebszentralen: {df_2025_monthly_bz[\"betriebszentrale\"].nunique()} branches')\nprint(f'  âœ“ Saved: data/processed/2025_actual_by_branch.csv')\nprint(f'\\n  Branch-level sample (first 5 rows):')\ndisplay(df_2025_monthly_bz[['date', 'betriebszentrale', 'total_orders', 'revenue_total']].head(5))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Plausibility Check - Compare 2025 vs 2024 Same Months\n",
    "\n",
    "Ensure 2025 data is comparable to 2024 (within Â±20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 2024 processed data for comparison\n",
    "print('Loading 2024 data for plausibility check...')\n",
    "df_2024_monthly = pd.read_csv('../data/processed/monthly_aggregated_full_company.csv')\n",
    "df_2024_monthly['date'] = pd.to_datetime(df_2024_monthly['date'])\n",
    "df_2024_monthly['year'] = df_2024_monthly['date'].dt.year\n",
    "df_2024_monthly['month'] = df_2024_monthly['date'].dt.month\n",
    "\n",
    "# Filter to 2024 data only\n",
    "df_2024_comparison = df_2024_monthly[df_2024_monthly['year'] == 2024].copy()\n",
    "print(f'  2024 data: {len(df_2024_comparison)} months')\n",
    "\n",
    "# Prepare 2025 data for comparison\n",
    "df_2025_comparison = df_2025_monthly.copy()\n",
    "df_2025_comparison['year'] = df_2025_comparison['date'].dt.year\n",
    "df_2025_comparison['month'] = df_2025_comparison['date'].dt.month\n",
    "print(f'  2025 data: {len(df_2025_comparison)} months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 2025 vs 2024 same months",
    "print('\\nPlausibility Check: 2025 vs 2024 Same Months')",
    "print('='*80)",
    "",
    "# Metrics to compare",
    "metrics = ['total_orders', 'revenue_total']",
    "",
    "# Merge on month for comparison",
    "comparison = df_2025_comparison[['month', 'total_orders', 'revenue_total']].merge(",
    "    df_2024_comparison[['month', 'total_orders', 'revenue_total']],",
    "    on='month',",
    "    suffixes=('_2025', '_2024'),",
    "    how='inner'",
    ")",
    "",
    "# Calculate percentage changes",
    "for metric in metrics:",
    "    comparison[f'{metric}_change_%'] = ((comparison[f'{metric}_2025'] - comparison[f'{metric}_2024']) / comparison[f'{metric}_2024'] * 100)",
    "",
    "# Add validation status",
    "def validate_change(change):",
    "    if -10 <= change <= 10:",
    "        return 'âœ“ Green (Normal)'",
    "    elif -20 <= change < -10 or 10 < change <= 20:",
    "        return 'âš ï¸  Yellow (Significant but plausible)'",
    "    else:",
    "        return 'âŒ Red (Investigate data quality)'",
    "",
    "# Display comparison",
    "month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep'}",
    "comparison['month_name'] = comparison['month'].map(month_names)",
    "",
    "print('\\nTotal Orders Comparison:')",
    "for _, row in comparison.iterrows():",
    "    change = row['total_orders_change_%']",
    "    status = validate_change(change)",
    "    print(f\"  {row['month_name']}: {row['total_orders_2025']:,.0f} vs {row['total_orders_2024']:,.0f} ({change:+.1f}%) {status}\")",
    "",
    "print('\\nRevenue Total Comparison:')",
    "for _, row in comparison.iterrows():",
    "    change = row['revenue_total_change_%']",
    "    status = validate_change(change)",
    "    print(f\"  {row['month_name']}: CHF {row['revenue_total_2025']:,.0f} vs CHF {row['revenue_total_2024']:,.0f} ({change:+.1f}%) {status}\")",
    "",
    "# Summary",
    "print('\\nPlausibility Summary:')",
    "for metric in metrics:",
    "    col = f'{metric}_change_%'",
    "    avg_change = comparison[col].mean()",
    "    max_change = comparison[col].max()",
    "    min_change = comparison[col].min()",
    "    print(f'  {metric}:')",
    "    print(f'    Average change: {avg_change:+.1f}%')",
    "    print(f'    Range: {min_change:+.1f}% to {max_change:+.1f}%')",
    "    # Check if any month is in red zone",
    "    red_months = comparison[comparison[col].abs() > 20]",
    "    if len(red_months) > 0:",
    "        print(f'    âš ï¸  {len(red_months)} month(s) in RED zone - investigate!')",
    "    else:",
    "        print(f'    âœ“ All months within acceptable range')",
    "",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Calculate Human Baseline Forecast\n",
    "\n",
    "Traditional budgeting method: 2024 annual total Ã· 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Calculating Human/Traditional Forecast (2024 total Ã· 12)...')\nprint('='*80)\n\n# Focus on key business metrics\ntarget_metrics = ['total_orders', 'revenue_total']\n\n# Calculate 2024 annual totals\nprint(f'\\n2024 Annual Totals:')\nhuman_forecast_values = {}\n\nfor metric in target_metrics:\n    if metric in df_2024_comparison.columns:\n        total_2024 = df_2024_comparison[metric].sum()\n        monthly_avg = total_2024 / 12\n        human_forecast_values[metric] = monthly_avg\n\n        if 'revenue' in metric:\n            print(f'  {metric:25s}: CHF {total_2024:,.2f} â†’ CHF {monthly_avg:,.2f}/month')\n        else:\n            print(f'  {metric:25s}: {total_2024:,.0f} â†’ {monthly_avg:,.0f}/month')\n    else:\n        print(f'  âš ï¸  {metric}: Not available in 2024 data')\n        human_forecast_values[metric] = 0\n\n# Create human forecast dataframe for Jan-Sep 2025\ndates_2025 = pd.date_range('2025-01-01', '2025-09-01', freq='MS')\ndf_human = pd.DataFrame({'date': dates_2025})\n\nfor metric in target_metrics:\n    df_human[metric] = human_forecast_values[metric]\n\ndf_human['method'] = 'Human (2024Ã·12)'\n\nprint(f'\\nâœ“ Human forecast created for {len(df_human)} months Ã— {len(target_metrics)} metrics')\nprint(f'  Metrics: {target_metrics}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Load Machine/ML Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Loading Machine/ML Forecasts...')\nprint('='*80)\n\n# Load consolidated forecasts (best model per metric)\ndf_ml_full = pd.read_csv('../data/processed/consolidated_forecast_2025.csv')\ndf_ml_full['date'] = pd.to_datetime(df_ml_full['date'])\n\n# Filter to Jan-Sep 2025 for comparison\ndf_ml = df_ml_full[(df_ml_full['date'] >= '2025-01-01') & (df_ml_full['date'] <= '2025-09-01')].copy()\ndf_ml['method'] = 'Machine (ML Models)'\n\n# Focus on key metrics\nfocus_metrics = ['total_orders', 'revenue_total']\navailable_metrics = [m for m in focus_metrics if m in df_ml.columns]\n\nprint(f'\\nâœ“ ML forecasts loaded: {len(df_ml)} months')\nprint(f'  Available metrics: {available_metrics}')\n\n# Display first few months\nprint(f'\\nML Forecast Sample (first 3 months):')\ndisplay_cols = ['date'] + available_metrics\ndisplay(df_ml[display_cols].head(3))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Calculate Error Metrics\n",
    "\n",
    "Compare both methods against actual 2025 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare actual data\n",
    "df_actual = df_2025_monthly[['date', 'total_orders', 'revenue_total']].copy()\n",
    "df_actual['method'] = 'Actual'\n",
    "\n",
    "# Merge all three datasets\n",
    "df_comparison = pd.concat([\n",
    "    df_actual.assign(source='Actual'),\n",
    "    df_human[['date', 'total_orders', 'revenue_total']].assign(source='Human'),\n",
    "    df_ml[['date', 'total_orders', 'revenue_total']].assign(source='Machine')\n",
    "], ignore_index=True)\n",
    "\n",
    "# Pivot for easier comparison\n",
    "metrics = ['total_orders', 'revenue_total']\n",
    "results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    pivot = df_comparison.pivot(index='date', columns='source', values=metric)\n",
    "    # Calculate errors\n",
    "    pivot['human_error'] = pivot['Human'] - pivot['Actual']\n",
    "    pivot['machine_error'] = pivot['Machine'] - pivot['Actual']\n",
    "    pivot['human_error_%'] = (pivot['human_error'] / pivot['Actual'] * 100)\n",
    "    pivot['machine_error_%'] = (pivot['machine_error'] / pivot['Actual'] * 100)\n",
    "    pivot['human_abs_error'] = pivot['human_error'].abs()\n",
    "    pivot['machine_abs_error'] = pivot['machine_error'].abs()\n",
    "    results[metric] = pivot\n",
    "\n",
    "print('Error Metrics Calculated')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "print('\\nSummary Statistics: TOTAL ORDERS')\n",
    "print('-'*80)\n",
    "\n",
    "orders_results = results['total_orders']\n",
    "\n",
    "# MAPE (Mean Absolute Percentage Error)\n",
    "human_mape = orders_results['human_error_%'].abs().mean()\n",
    "machine_mape = orders_results['machine_error_%'].abs().mean()\n",
    "\n",
    "# MAE (Mean Absolute Error)\n",
    "human_mae = orders_results['human_abs_error'].mean()\n",
    "machine_mae = orders_results['machine_abs_error'].mean()\n",
    "\n",
    "# Cumulative Error\n",
    "human_cumulative = orders_results['human_error'].sum()\n",
    "machine_cumulative = orders_results['machine_error'].sum()\n",
    "\n",
    "print(f'\\nHuman Method (2024Ã·12):')\n",
    "print(f'  MAPE: {human_mape:.2f}%')\n",
    "print(f'  MAE: {human_mae:,.0f} orders')\n",
    "print(f'  Cumulative Error (Jan-Sep): {human_cumulative:,.0f} orders')\n",
    "\n",
    "print(f'\\nMachine Method (ML Models):')\n",
    "print(f'  MAPE: {machine_mape:.2f}%')\n",
    "print(f'  MAE: {machine_mae:,.0f} orders')\n",
    "print(f'  Cumulative Error (Jan-Sep): {machine_cumulative:,.0f} orders')\n",
    "\n",
    "improvement_mape = ((human_mape - machine_mape) / human_mape * 100)\n",
    "print(f'\\nâœ“ ML Improvement over Human: {improvement_mape:.1f}% reduction in MAPE')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('Summary Statistics: REVENUE TOTAL')\n",
    "print('-'*80)\n",
    "\n",
    "revenue_results = results['revenue_total']\n",
    "\n",
    "# MAPE\n",
    "human_mape_rev = revenue_results['human_error_%'].abs().mean()\n",
    "machine_mape_rev = revenue_results['machine_error_%'].abs().mean()\n",
    "\n",
    "# MAE\n",
    "human_mae_rev = revenue_results['human_abs_error'].mean()\n",
    "machine_mae_rev = revenue_results['machine_abs_error'].mean()\n",
    "\n",
    "# Cumulative Error\n",
    "human_cumulative_rev = revenue_results['human_error'].sum()\n",
    "machine_cumulative_rev = revenue_results['machine_error'].sum()\n",
    "\n",
    "print(f'\\nHuman Method (2024Ã·12):')\n",
    "print(f'  MAPE: {human_mape_rev:.2f}%')\n",
    "print(f'  MAE: CHF {human_mae_rev:,.0f}')\n",
    "print(f'  Cumulative Error (Jan-Sep): CHF {human_cumulative_rev:,.0f}')\n",
    "\n",
    "print(f'\\nMachine Method (ML Models):')\n",
    "print(f'  MAPE: {machine_mape_rev:.2f}%')\n",
    "print(f'  MAE: CHF {machine_mae_rev:,.0f}')\n",
    "print(f'  Cumulative Error (Jan-Sep): CHF {machine_cumulative_rev:,.0f}')\n",
    "\n",
    "improvement_mape_rev = ((human_mape_rev - machine_mape_rev) / human_mape_rev * 100)\n",
    "print(f'\\nâœ“ ML Improvement over Human: {improvement_mape_rev:.1f}% reduction in MAPE')\n",
    "\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Create Visualizations\n",
    "\n",
    "**The Most Crucial Visualization**: Human Error vs Machine Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Monthly Comparison - Total Orders\n",
    "fig1 = go.Figure()\n",
    "\n",
    "# Actual data\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['Actual'],\n",
    "    mode='lines+markers',\n",
    "    name='Actual 2025',\n",
    "    line=dict(color='black', width=3),\n",
    "    marker=dict(size=10)\n",
    "))\n",
    "\n",
    "# Human forecast\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['Human'],\n",
    "    mode='lines+markers',\n",
    "    name='Human (2024Ã·12)',\n",
    "    line=dict(color='#FF6B6B', width=2, dash='dash'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "# Machine forecast\n",
    "fig1.add_trace(go.Scatter(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['Machine'],\n",
    "    mode='lines+markers',\n",
    "    name='Machine (ML)',\n",
    "    line=dict(color='#4ECDC4', width=2, dash='dot'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig1.update_layout(\n",
    "    title='Total Orders: Actual vs Human vs Machine Forecasts (Jan-Sep 2025)',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Total Orders',\n",
    "    hovermode='x unified',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "# Save\n",
    "fig1.write_html('../results/forecast_validation_orders_comparison.html')\n",
    "print('âœ“ Saved: results/forecast_validation_orders_comparison.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Monthly Comparison - Revenue Total\n",
    "fig2 = go.Figure()\n",
    "\n",
    "# Actual data\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['Actual'],\n",
    "    mode='lines+markers',\n",
    "    name='Actual 2025',\n",
    "    line=dict(color='black', width=3),\n",
    "    marker=dict(size=10)\n",
    "))\n",
    "\n",
    "# Human forecast\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['Human'],\n",
    "    mode='lines+markers',\n",
    "    name='Human (2024Ã·12)',\n",
    "    line=dict(color='#FF6B6B', width=2, dash='dash'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "# Machine forecast\n",
    "fig2.add_trace(go.Scatter(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['Machine'],\n",
    "    mode='lines+markers',\n",
    "    name='Machine (ML)',\n",
    "    line=dict(color='#4ECDC4', width=2, dash='dot'),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='Revenue Total: Actual vs Human vs Machine Forecasts (Jan-Sep 2025)',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Revenue (CHF)',\n",
    "    hovermode='x unified',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "# Save\n",
    "fig2.write_html('../results/forecast_validation_revenue_comparison.html')\n",
    "print('âœ“ Saved: results/forecast_validation_revenue_comparison.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: THE CRUCIAL ONE - Error Comparison Side-by-Side\n",
    "fig3 = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        'Total Orders: Human Error (%)',\n",
    "        'Total Orders: Machine Error (%)',\n",
    "        'Revenue Total: Human Error (%)',\n",
    "        'Revenue Total: Machine Error (%)'\n",
    "    ],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "# Orders - Human Error\n",
    "fig3.add_trace(go.Bar(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['human_error_%'],\n",
    "    marker_color='#FF6B6B',\n",
    "    name='Human Error',\n",
    "    showlegend=False\n",
    "), row=1, col=1)\n",
    "\n",
    "# Orders - Machine Error\n",
    "fig3.add_trace(go.Bar(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['machine_error_%'],\n",
    "    marker_color='#4ECDC4',\n",
    "    name='Machine Error',\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# Revenue - Human Error\n",
    "fig3.add_trace(go.Bar(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['human_error_%'],\n",
    "    marker_color='#FF6B6B',\n",
    "    name='Human Error',\n",
    "    showlegend=False\n",
    "), row=2, col=1)\n",
    "\n",
    "# Revenue - Machine Error\n",
    "fig3.add_trace(go.Bar(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['machine_error_%'],\n",
    "    marker_color='#4ECDC4',\n",
    "    name='Machine Error',\n",
    "    showlegend=False\n",
    "), row=2, col=2)\n",
    "\n",
    "# Add zero line to all subplots\n",
    "for row in [1, 2]:\n",
    "    for col in [1, 2]:\n",
    "        fig3.add_hline(y=0, line_dash='dash', line_color='gray', row=row, col=col)\n",
    "\n",
    "fig3.update_layout(\n",
    "    title_text='<b>Human vs Machine Forecast Error Comparison (Jan-Sep 2025)</b>',\n",
    "    title_font_size=18,\n",
    "    height=800,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Update y-axes labels\n",
    "fig3.update_yaxes(title_text='Error (%)', row=1, col=1)\n",
    "fig3.update_yaxes(title_text='Error (%)', row=1, col=2)\n",
    "fig3.update_yaxes(title_text='Error (%)', row=2, col=1)\n",
    "fig3.update_yaxes(title_text='Error (%)', row=2, col=2)\n",
    "\n",
    "fig3.show()\n",
    "\n",
    "# Save\n",
    "fig3.write_html('../results/forecast_validation_error_comparison.html')\n",
    "print('âœ“ Saved: results/forecast_validation_error_comparison.html')\n",
    "print('\\nðŸŽ¯ THIS IS THE MOST CRUCIAL VISUALIZATION OF THE WHOLE PROJECT!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Cumulative Error Over Time\n",
    "fig4 = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Total Orders: Cumulative Error', 'Revenue Total: Cumulative Error']\n",
    ")\n",
    "\n",
    "# Orders cumulative error\n",
    "fig4.add_trace(go.Scatter(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['human_error'].cumsum(),\n",
    "    mode='lines+markers',\n",
    "    name='Human',\n",
    "    line=dict(color='#FF6B6B', width=2)\n",
    "), row=1, col=1)\n",
    "\n",
    "fig4.add_trace(go.Scatter(\n",
    "    x=orders_results.index,\n",
    "    y=orders_results['machine_error'].cumsum(),\n",
    "    mode='lines+markers',\n",
    "    name='Machine',\n",
    "    line=dict(color='#4ECDC4', width=2)\n",
    "), row=1, col=1)\n",
    "\n",
    "# Revenue cumulative error\n",
    "fig4.add_trace(go.Scatter(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['human_error'].cumsum(),\n",
    "    mode='lines+markers',\n",
    "    name='Human',\n",
    "    line=dict(color='#FF6B6B', width=2),\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "fig4.add_trace(go.Scatter(\n",
    "    x=revenue_results.index,\n",
    "    y=revenue_results['machine_error'].cumsum(),\n",
    "    mode='lines+markers',\n",
    "    name='Machine',\n",
    "    line=dict(color='#4ECDC4', width=2),\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# Add zero lines\n",
    "fig4.add_hline(y=0, line_dash='dash', line_color='gray', row=1, col=1)\n",
    "fig4.add_hline(y=0, line_dash='dash', line_color='gray', row=1, col=2)\n",
    "\n",
    "fig4.update_layout(\n",
    "    title='Cumulative Forecast Error (Jan-Sep 2025)',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig4.update_yaxes(title_text='Cumulative Error (Orders)', row=1, col=1)\n",
    "fig4.update_yaxes(title_text='Cumulative Error (CHF)', row=1, col=2)\n",
    "\n",
    "fig4.show()\n",
    "\n",
    "# Save\n",
    "fig4.write_html('../results/forecast_validation_cumulative_error.html')\n",
    "print('âœ“ Saved: results/forecast_validation_cumulative_error.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Error Distribution Box Plot\n",
    "fig5 = go.Figure()\n",
    "\n",
    "# Orders\n",
    "fig5.add_trace(go.Box(\n",
    "    y=orders_results['human_error_%'],\n",
    "    name='Human (Orders)',\n",
    "    marker_color='#FF6B6B',\n",
    "    boxmean='sd'\n",
    "))\n",
    "\n",
    "fig5.add_trace(go.Box(\n",
    "    y=orders_results['machine_error_%'],\n",
    "    name='Machine (Orders)',\n",
    "    marker_color='#4ECDC4',\n",
    "    boxmean='sd'\n",
    "))\n",
    "\n",
    "# Revenue\n",
    "fig5.add_trace(go.Box(\n",
    "    y=revenue_results['human_error_%'],\n",
    "    name='Human (Revenue)',\n",
    "    marker_color='#FFB6C1',\n",
    "    boxmean='sd'\n",
    "))\n",
    "\n",
    "fig5.add_trace(go.Box(\n",
    "    y=revenue_results['machine_error_%'],\n",
    "    name='Machine (Revenue)',\n",
    "    marker_color='#95E1D3',\n",
    "    boxmean='sd'\n",
    "))\n",
    "\n",
    "fig5.add_hline(y=0, line_dash='dash', line_color='gray')\n",
    "\n",
    "fig5.update_layout(\n",
    "    title='Forecast Error Distribution (Jan-Sep 2025)',\n",
    "    yaxis_title='Error (%)',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig5.show()\n",
    "\n",
    "# Save\n",
    "fig5.write_html('../results/forecast_validation_error_distribution.html')\n",
    "print('âœ“ Saved: results/forecast_validation_error_distribution.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Executive Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create executive summary table\n",
    "summary_data = {\n",
    "    'Metric': ['Total Orders', 'Total Orders', 'Revenue Total', 'Revenue Total'],\n",
    "    'Method': ['Human (2024Ã·12)', 'Machine (ML)', 'Human (2024Ã·12)', 'Machine (ML)'],\n",
    "    'MAPE (%)': [human_mape, machine_mape, human_mape_rev, machine_mape_rev],\n",
    "    'MAE': [human_mae, machine_mae, human_mae_rev, machine_mae_rev],\n",
    "    'Cumulative Error': [human_cumulative, machine_cumulative, human_cumulative_rev, machine_cumulative_rev]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print('\\nExecutive Summary: Forecast Validation Results (Jan-Sep 2025)')\n",
    "print('='*80)\n",
    "display(df_summary)\n",
    "\n",
    "# Save to CSV\n",
    "df_summary.to_csv('../results/forecast_validation_summary.csv', index=False)\n",
    "print('\\nâœ“ Saved: results/forecast_validation_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('FORECAST VALIDATION INSIGHTS')\n",
    "print('='*80)\n",
    "\n",
    "print('\\n1. ACCURACY COMPARISON:')\n",
    "print(f'   Total Orders:')\n",
    "print(f'     - Human MAPE: {human_mape:.2f}%')\n",
    "print(f'     - Machine MAPE: {machine_mape:.2f}%')\n",
    "print(f'     - Improvement: {improvement_mape:.1f}%')\n",
    "print(f'\\n   Revenue Total:')\n",
    "print(f'     - Human MAPE: {human_mape_rev:.2f}%')\n",
    "print(f'     - Machine MAPE: {machine_mape_rev:.2f}%')\n",
    "print(f'     - Improvement: {improvement_mape_rev:.1f}%')\n",
    "\n",
    "print('\\n2. CUMULATIVE IMPACT (Jan-Sep 2025):')\n",
    "print(f'   Total Orders:')\n",
    "print(f'     - Human cumulative error: {human_cumulative:,.0f} orders')\n",
    "print(f'     - Machine cumulative error: {machine_cumulative:,.0f} orders')\n",
    "print(f'     - Difference: {abs(human_cumulative - machine_cumulative):,.0f} orders')\n",
    "print(f'\\n   Revenue Total:')\n",
    "print(f'     - Human cumulative error: CHF {human_cumulative_rev:,.0f}')\n",
    "print(f'     - Machine cumulative error: CHF {machine_cumulative_rev:,.0f}')\n",
    "print(f'     - Difference: CHF {abs(human_cumulative_rev - machine_cumulative_rev):,.0f}')\n",
    "\n",
    "print('\\n3. KEY FINDINGS:')\n",
    "if machine_mape < human_mape:\n",
    "    print(f'   âœ“ ML models outperform traditional method by {improvement_mape:.1f}% for orders')\n",
    "else:\n",
    "    print(f'   âš ï¸  Traditional method performs better for orders by {-improvement_mape:.1f}%')\n",
    "\n",
    "if machine_mape_rev < human_mape_rev:\n",
    "    print(f'   âœ“ ML models outperform traditional method by {improvement_mape_rev:.1f}% for revenue')\n",
    "else:\n",
    "    print(f'   âš ï¸  Traditional method performs better for revenue by {-improvement_mape_rev:.1f}%')\n",
    "\n",
    "print('\\n4. RECOMMENDATIONS:')\n",
    "if machine_mape < human_mape and machine_mape_rev < human_mape_rev:\n",
    "    print('   âœ“ ADOPT ML forecasting for both orders and revenue planning')\n",
    "    print('   âœ“ Replace 2024Ã·12 method with ML-based forecasts')\n",
    "    print('   âœ“ Monitor monthly actuals vs forecasts to track ongoing accuracy')\n",
    "elif machine_mape < human_mape or machine_mape_rev < human_mape_rev:\n",
    "    print('   âš ï¸  Consider hybrid approach: ML for some metrics, traditional for others')\n",
    "    print('   âš ï¸  Continue validation with additional months of data')\n",
    "else:\n",
    "    print('   âš ï¸  Further model refinement needed before deployment')\n",
    "    print('   âš ï¸  Investigate why ML models underperform')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('VALIDATION COMPLETE')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed monthly comparison\n",
    "monthly_comparison = pd.DataFrame({\n",
    "    'date': orders_results.index,\n",
    "    'orders_actual': orders_results['Actual'],\n",
    "    'orders_human': orders_results['Human'],\n",
    "    'orders_machine': orders_results['Machine'],\n",
    "    'orders_human_error_%': orders_results['human_error_%'],\n",
    "    'orders_machine_error_%': orders_results['machine_error_%'],\n",
    "    'revenue_actual': revenue_results['Actual'],\n",
    "    'revenue_human': revenue_results['Human'],\n",
    "    'revenue_machine': revenue_results['Machine'],\n",
    "    'revenue_human_error_%': revenue_results['human_error_%'],\n",
    "    'revenue_machine_error_%': revenue_results['machine_error_%']\n",
    "})\n",
    "\n",
    "monthly_comparison.to_csv('../results/forecast_validation_monthly_detail.csv', index=False)\n",
    "print('\\nâœ“ Saved detailed monthly comparison: results/forecast_validation_monthly_detail.csv')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('ALL OUTPUTS SAVED TO: /Users/kk/dev/customer_traveco/results/')\n",
    "print('='*80)\n",
    "print('Files created:')\n",
    "print('  1. forecast_validation_orders_comparison.html (interactive)')\n",
    "print('  2. forecast_validation_revenue_comparison.html (interactive)')\n",
    "print('  3. forecast_validation_error_comparison.html (MOST CRUCIAL)')\n",
    "print('  4. forecast_validation_cumulative_error.html (interactive)')\n",
    "print('  5. forecast_validation_error_distribution.html (interactive)')\n",
    "print('  6. forecast_validation_summary.csv (executive summary)')\n",
    "print('  7. forecast_validation_monthly_detail.csv (detailed data)')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 10: Comprehensive Model Comparison - ALL Forecasting Approaches\n\n**Goal**: Compare ALL 5 forecasting approaches to understand which truly performs best:\n1. **Seasonal Naive** (current consolidated forecast)\n2. **XGBoost** (original \"best\" model from training)\n3. **CatBoost** (alternative ML model)\n4. **Ensemble Best** (model selection from 14b)\n5. **Human Baseline** (2024Ã·12)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print('Loading ALL Forecasting Approaches for Comprehensive Comparison...')\nprint('='*80)\n\n# Dictionary to store all forecasts\nall_forecasts = {}\n\n# 1. Seasonal Naive (from consolidated_forecast_2025.csv)\nprint('\\n1. Loading Seasonal Naive (from consolidated forecast)...')\ndf_seasonal_naive = pd.read_csv('../data/processed/consolidated_forecast_2025.csv')\ndf_seasonal_naive['date'] = pd.to_datetime(df_seasonal_naive['date'])\ndf_seasonal_naive = df_seasonal_naive[(df_seasonal_naive['date'] >= '2025-01-01') & \n                                      (df_seasonal_naive['date'] <= '2025-09-01')].copy()\nall_forecasts['Seasonal_Naive'] = df_seasonal_naive[['date', 'total_orders', 'revenue_total']].copy()\nprint(f'   âœ“ Seasonal Naive loaded: {len(all_forecasts[\"Seasonal_Naive\"])} months')\nprint(f'     Jan Orders: {df_seasonal_naive.iloc[0][\"total_orders\"]:,.0f}')\nprint(f'     Jan Revenue: CHF {df_seasonal_naive.iloc[0][\"revenue_total\"]:,.0f}')\n\n# 2. XGBoost\nprint('\\n2. Loading XGBoost forecasts...')\ntry:\n    df_xgboost = pd.read_csv('../data/processed/xgboost_forecast_2025.csv')\n    df_xgboost['date'] = pd.to_datetime(df_xgboost['date'])\n    df_xgboost = df_xgboost[(df_xgboost['date'] >= '2025-01-01') & \n                            (df_xgboost['date'] <= '2025-09-01')].copy()\n    all_forecasts['XGBoost'] = df_xgboost[['date', 'total_orders', 'revenue_total']].copy()\n    print(f'   âœ“ XGBoost loaded: {len(all_forecasts[\"XGBoost\"])} months')\n    print(f'     Jan Orders: {df_xgboost.iloc[0][\"total_orders\"]:,.0f}')\n    print(f'     Jan Revenue: CHF {df_xgboost.iloc[0][\"revenue_total\"]:,.0f}')\nexcept FileNotFoundError:\n    print('   âš ï¸  XGBoost forecast file not found')\n    all_forecasts['XGBoost'] = None\n\n# 3. CatBoost\nprint('\\n3. Loading CatBoost forecasts...')\ntry:\n    df_catboost = pd.read_csv('../data/processed/catboost_forecast_2025.csv')\n    df_catboost['date'] = pd.to_datetime(df_catboost['date'])\n    df_catboost = df_catboost[(df_catboost['date'] >= '2025-01-01') & \n                              (df_catboost['date'] <= '2025-09-01')].copy()\n    all_forecasts['CatBoost'] = df_catboost[['date', 'total_orders', 'revenue_total']].copy()\n    print(f'   âœ“ CatBoost loaded: {len(all_forecasts[\"CatBoost\"])} months')\n    print(f'     Jan Orders: {df_catboost.iloc[0][\"total_orders\"]:,.0f}')\n    print(f'     Jan Revenue: CHF {df_catboost.iloc[0][\"revenue_total\"]:,.0f}')\nexcept FileNotFoundError:\n    print('   âš ï¸  CatBoost forecast file not found')\n    all_forecasts['CatBoost'] = None\n\n# 4. Ensemble Best Model\nprint('\\n4. Loading Ensemble Best Model forecasts...')\ntry:\n    df_ensemble = pd.read_csv('../data/processed/ensemble_best_model_2025.csv')\n    df_ensemble['date'] = pd.to_datetime(df_ensemble['date'])\n    df_ensemble = df_ensemble[(df_ensemble['date'] >= '2025-01-01') & \n                             (df_ensemble['date'] <= '2025-09-01')].copy()\n    all_forecasts['Ensemble_Best'] = df_ensemble[['date', 'total_orders', 'revenue_total']].copy()\n    print(f'   âœ“ Ensemble Best loaded: {len(all_forecasts[\"Ensemble_Best\"])} months')\n    print(f'     Jan Orders: {df_ensemble.iloc[0][\"total_orders\"]:,.0f}')\n    print(f'     Jan Revenue: CHF {df_ensemble.iloc[0][\"revenue_total\"]:,.0f}')\nexcept FileNotFoundError:\n    print('   âš ï¸  Ensemble forecast file not found')\n    all_forecasts['Ensemble_Best'] = None\n\n# 5. Human Baseline (already loaded)\nall_forecasts['Human'] = df_human[['date', 'total_orders', 'revenue_total']].copy()\nprint('\\n5. Human Baseline (2024Ã·12):')\nprint(f'   âœ“ Human forecast loaded: {len(all_forecasts[\"Human\"])} months')\nprint(f'     Monthly Orders: {df_human.iloc[0][\"total_orders\"]:,.0f}')\nprint(f'     Monthly Revenue: CHF {df_human.iloc[0][\"revenue_total\"]:,.0f}')\n\n# Summary\nprint(f'\\n{\"=\"*80}')\nprint('SUMMARY:')\navailable_approaches = [k for k, v in all_forecasts.items() if v is not None]\nprint(f'  Total approaches loaded: {len(available_approaches)}')\nprint(f'  Approaches: {\", \".join(available_approaches)}')\nprint('='*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print('Calculating MAPE and MAE for ALL Approaches...')\nprint('='*80)\n\n# Prepare actual data for comparison\ndf_actual_comp = df_2025_monthly[['date', 'total_orders', 'revenue_total']].copy()\n\n# Dictionary to store results\nall_results = {}\nmetrics_to_compare = ['total_orders', 'revenue_total']\n\nfor approach_name, forecast_df in all_forecasts.items():\n    if forecast_df is None:\n        print(f'\\nâš ï¸  Skipping {approach_name} (not available)')\n        continue\n    \n    print(f'\\n{approach_name}:')\n    all_results[approach_name] = {}\n    \n    for metric in metrics_to_compare:\n        # Merge actual with forecast\n        merged = df_actual_comp[['date', metric]].merge(\n            forecast_df[['date', metric]],\n            on='date',\n            suffixes=('_actual', '_forecast'),\n            how='inner'\n        )\n        \n        # Calculate errors\n        merged['error'] = merged[f'{metric}_forecast'] - merged[f'{metric}_actual']\n        merged['error_%'] = (merged['error'] / merged[f'{metric}_actual'] * 100)\n        merged['abs_error'] = merged['error'].abs()\n        merged['abs_error_%'] = merged['error_%'].abs()\n        \n        # Calculate metrics\n        mape = merged['abs_error_%'].mean()\n        mae = merged['abs_error'].mean()\n        cumulative_error = merged['error'].sum()\n        \n        # Store results\n        all_results[approach_name][metric] = {\n            'mape': mape,\n            'mae': mae,\n            'cumulative_error': cumulative_error,\n            'monthly_errors': merged['error_%'].tolist()\n        }\n        \n        # Print results\n        if 'revenue' in metric:\n            print(f'  {metric:20s}: MAPE={mape:5.2f}%  MAE=CHF {mae:,.0f}  Cumulative=CHF {cumulative_error:,.0f}')\n        else:\n            print(f'  {metric:20s}: MAPE={mape:5.2f}%  MAE={mae:,.0f}  Cumulative={cumulative_error:,.0f}')\n\nprint('\\n' + '='*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print('Creating Comprehensive Comparison Summary Table...')\nprint('='*80)\n\n# Create summary dataframe\nsummary_rows = []\n\nfor approach_name in all_results.keys():\n    for metric in metrics_to_compare:\n        results = all_results[approach_name][metric]\n        summary_rows.append({\n            'Approach': approach_name,\n            'Metric': metric,\n            'MAPE (%)': results['mape'],\n            'MAE': results['mae'],\n            'Cumulative Error': results['cumulative_error']\n        })\n\ndf_all_approaches_summary = pd.DataFrame(summary_rows)\n\n# Pivot for easier comparison\nprint('\\nðŸ“Š COMPREHENSIVE MAPE COMPARISON (Lower is Better):')\nprint('='*80)\n\n# Orders comparison\nprint('\\n** TOTAL ORDERS **')\norders_pivot = df_all_approaches_summary[df_all_approaches_summary['Metric'] == 'total_orders'].copy()\norders_pivot = orders_pivot.sort_values('MAPE (%)')\nprint(orders_pivot[['Approach', 'MAPE (%)', 'MAE', 'Cumulative Error']].to_string(index=False))\n\n# Identify winner\nbest_orders = orders_pivot.iloc[0]['Approach']\nbest_orders_mape = orders_pivot.iloc[0]['MAPE (%)']\nprint(f'\\nðŸ† WINNER (Orders): {best_orders} with MAPE = {best_orders_mape:.2f}%')\n\n# Revenue comparison\nprint('\\n\\n** REVENUE TOTAL **')\nrevenue_pivot = df_all_approaches_summary[df_all_approaches_summary['Metric'] == 'revenue_total'].copy()\nrevenue_pivot = revenue_pivot.sort_values('MAPE (%)')\nprint(revenue_pivot[['Approach', 'MAPE (%)', 'MAE', 'Cumulative Error']].to_string(index=False))\n\n# Identify winner\nbest_revenue = revenue_pivot.iloc[0]['Approach']\nbest_revenue_mape = revenue_pivot.iloc[0]['MAPE (%)']\nprint(f'\\nðŸ† WINNER (Revenue): {best_revenue} with MAPE = {best_revenue_mape:.2f}%')\n\n# Save comprehensive summary\ndf_all_approaches_summary.to_csv('../results/forecast_validation_all_approaches_summary.csv', index=False)\nprint(f'\\nâœ“ Saved: results/forecast_validation_all_approaches_summary.csv')\nprint('='*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print('Creating Comprehensive Visualization: All Approaches Comparison...')\nprint('='*80)\n\n# Create interactive comparison chart - ORDERS\nfig_all_orders = go.Figure()\n\n# Add actual data\nfig_all_orders.add_trace(go.Scatter(\n    x=df_actual_comp['date'],\n    y=df_actual_comp['total_orders'],\n    mode='lines+markers',\n    name='Actual 2025',\n    line=dict(color='black', width=4),\n    marker=dict(size=12, symbol='diamond')\n))\n\n# Color scheme for different approaches\ncolors = {\n    'Seasonal_Naive': '#FF6B6B',\n    'XGBoost': '#4ECDC4',\n    'CatBoost': '#95E1D3',\n    'Ensemble_Best': '#FFD93D',\n    'Human': '#A8E6CF'\n}\n\n# Add all forecast approaches\nfor approach_name, forecast_df in all_forecasts.items():\n    if forecast_df is None:\n        continue\n    \n    mape = all_results[approach_name]['total_orders']['mape']\n    \n    fig_all_orders.add_trace(go.Scatter(\n        x=forecast_df['date'],\n        y=forecast_df['total_orders'],\n        mode='lines+markers',\n        name=f'{approach_name} (MAPE={mape:.2f}%)',\n        line=dict(color=colors.get(approach_name, '#999999'), width=2),\n        marker=dict(size=8)\n    ))\n\nfig_all_orders.update_layout(\n    title='<b>Total Orders: All Forecasting Approaches vs Actual (Jan-Sep 2025)</b>',\n    xaxis_title='Month',\n    yaxis_title='Total Orders',\n    hovermode='x unified',\n    height=600,\n    template='plotly_white',\n    legend=dict(\n        orientation='v',\n        yanchor='top',\n        y=0.99,\n        xanchor='left',\n        x=0.01,\n        bgcolor='rgba(255, 255, 255, 0.9)'\n    )\n)\n\nfig_all_orders.show()\n\n# Save\nfig_all_orders.write_html('../results/forecast_validation_all_approaches_orders.html')\nprint('âœ“ Saved: results/forecast_validation_all_approaches_orders.html')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create interactive comparison chart - REVENUE\nfig_all_revenue = go.Figure()\n\n# Add actual data\nfig_all_revenue.add_trace(go.Scatter(\n    x=df_actual_comp['date'],\n    y=df_actual_comp['revenue_total'],\n    mode='lines+markers',\n    name='Actual 2025',\n    line=dict(color='black', width=4),\n    marker=dict(size=12, symbol='diamond')\n))\n\n# Add all forecast approaches\nfor approach_name, forecast_df in all_forecasts.items():\n    if forecast_df is None:\n        continue\n    \n    mape = all_results[approach_name]['revenue_total']['mape']\n    \n    fig_all_revenue.add_trace(go.Scatter(\n        x=forecast_df['date'],\n        y=forecast_df['revenue_total'],\n        mode='lines+markers',\n        name=f'{approach_name} (MAPE={mape:.2f}%)',\n        line=dict(color=colors.get(approach_name, '#999999'), width=2),\n        marker=dict(size=8)\n    ))\n\nfig_all_revenue.update_layout(\n    title='<b>Revenue Total: All Forecasting Approaches vs Actual (Jan-Sep 2025)</b>',\n    xaxis_title='Month',\n    yaxis_title='Revenue (CHF)',\n    hovermode='x unified',\n    height=600,\n    template='plotly_white',\n    legend=dict(\n        orientation='v',\n        yanchor='top',\n        y=0.99,\n        xanchor='left',\n        x=0.01,\n        bgcolor='rgba(255, 255, 255, 0.9)'\n    )\n)\n\nfig_all_revenue.show()\n\n# Save\nfig_all_revenue.write_html('../results/forecast_validation_all_approaches_revenue.html')\nprint('âœ“ Saved: results/forecast_validation_all_approaches_revenue.html')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print('Creating MAPE Ranking Bar Chart...')\nprint('='*80)\n\n# Create side-by-side MAPE comparison\nfig_mape_comparison = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=['Total Orders - MAPE Comparison', 'Revenue Total - MAPE Comparison'],\n    horizontal_spacing=0.15\n)\n\n# Prepare data for orders\norders_mape_data = []\nfor approach_name in all_results.keys():\n    mape = all_results[approach_name]['total_orders']['mape']\n    orders_mape_data.append({'Approach': approach_name, 'MAPE': mape})\n\ndf_orders_mape = pd.DataFrame(orders_mape_data).sort_values('MAPE')\n\n# Prepare data for revenue\nrevenue_mape_data = []\nfor approach_name in all_results.keys():\n    mape = all_results[approach_name]['revenue_total']['mape']\n    revenue_mape_data.append({'Approach': approach_name, 'MAPE': mape})\n\ndf_revenue_mape = pd.DataFrame(revenue_mape_data).sort_values('MAPE')\n\n# Add orders MAPE bars\nfig_mape_comparison.add_trace(go.Bar(\n    x=df_orders_mape['Approach'],\n    y=df_orders_mape['MAPE'],\n    marker_color=['#2ECC71' if i == 0 else '#E74C3C' if i == len(df_orders_mape)-1 else '#3498DB' \n                  for i in range(len(df_orders_mape))],\n    text=[f'{v:.2f}%' for v in df_orders_mape['MAPE']],\n    textposition='outside',\n    showlegend=False\n), row=1, col=1)\n\n# Add revenue MAPE bars\nfig_mape_comparison.add_trace(go.Bar(\n    x=df_revenue_mape['Approach'],\n    y=df_revenue_mape['MAPE'],\n    marker_color=['#2ECC71' if i == 0 else '#E74C3C' if i == len(df_revenue_mape)-1 else '#3498DB' \n                  for i in range(len(df_revenue_mape))],\n    text=[f'{v:.2f}%' for v in df_revenue_mape['MAPE']],\n    textposition='outside',\n    showlegend=False\n), row=1, col=2)\n\nfig_mape_comparison.update_layout(\n    title_text='<b>MAPE Comparison: All Forecasting Approaches (Lower is Better)</b>',\n    title_font_size=18,\n    height=500,\n    template='plotly_white'\n)\n\nfig_mape_comparison.update_yaxes(title_text='MAPE (%)', row=1, col=1)\nfig_mape_comparison.update_yaxes(title_text='MAPE (%)', row=1, col=2)\n\nfig_mape_comparison.show()\n\n# Save\nfig_mape_comparison.write_html('../results/forecast_validation_all_approaches_mape_ranking.html')\nprint('âœ“ Saved: results/forecast_validation_all_approaches_mape_ranking.html')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 11: Final Recommendations - All Approaches Evaluated",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print('\\n' + '='*80)\nprint('FINAL RECOMMENDATIONS: ALL FORECASTING APPROACHES EVALUATED')\nprint('='*80)\n\nprint('\\nðŸ“Š PERFORMANCE RANKINGS:')\nprint('\\n1. Total Orders (Jan-Sep 2025):')\nprint('-' * 60)\nfor i, row in df_orders_mape.iterrows():\n    rank = list(df_orders_mape.index).index(i) + 1\n    medal = 'ðŸ¥‡' if rank == 1 else 'ðŸ¥ˆ' if rank == 2 else 'ðŸ¥‰' if rank == 3 else f'  {rank}.'\n    print(f'   {medal} {row[\"Approach\"]:20s} MAPE = {row[\"MAPE\"]:5.2f}%')\n\nprint('\\n2. Revenue Total (Jan-Sep 2025):')\nprint('-' * 60)\nfor i, row in df_revenue_mape.iterrows():\n    rank = list(df_revenue_mape.index).index(i) + 1\n    medal = 'ðŸ¥‡' if rank == 1 else 'ðŸ¥ˆ' if rank == 2 else 'ðŸ¥‰' if rank == 3 else f'  {rank}.'\n    print(f'   {medal} {row[\"Approach\"]:20s} MAPE = {row[\"MAPE\"]:5.2f}%')\n\nprint('\\n\\nðŸŽ¯ KEY FINDINGS:')\nprint('-' * 80)\n\n# Find best approach for each metric\nbest_orders_approach = df_orders_mape.iloc[0]['Approach']\nbest_orders_mape_val = df_orders_mape.iloc[0]['MAPE']\nworst_orders_approach = df_orders_mape.iloc[-1]['Approach']\nworst_orders_mape_val = df_orders_mape.iloc[-1]['MAPE']\n\nbest_revenue_approach = df_revenue_mape.iloc[0]['Approach']\nbest_revenue_mape_val = df_revenue_mape.iloc[0]['MAPE']\nworst_revenue_approach = df_revenue_mape.iloc[-1]['Approach']\nworst_revenue_mape_val = df_revenue_mape.iloc[-1]['MAPE']\n\nprint(f'\\n1. BEST PERFORMERS:')\nprint(f'   - Orders:  {best_orders_approach} ({best_orders_mape_val:.2f}% MAPE)')\nprint(f'   - Revenue: {best_revenue_approach} ({best_revenue_mape_val:.2f}% MAPE)')\n\nprint(f'\\n2. WORST PERFORMERS:')\nprint(f'   - Orders:  {worst_orders_approach} ({worst_orders_mape_val:.2f}% MAPE)')\nprint(f'   - Revenue: {worst_revenue_approach} ({worst_revenue_mape_val:.2f}% MAPE)')\n\nprint(f'\\n3. PERFORMANCE SPREAD:')\nprint(f'   - Orders:  {worst_orders_mape_val - best_orders_mape_val:.2f}% difference between best and worst')\nprint(f'   - Revenue: {worst_revenue_mape_val - best_revenue_mape_val:.2f}% difference between best and worst')\n\nprint('\\n\\nâœ… FINAL RECOMMENDATION:')\nprint('='*80)\n\n# Logic for recommendation\nif best_orders_approach == best_revenue_approach:\n    print(f'\\nðŸŽ¯ CLEAR WINNER: {best_orders_approach}')\n    print(f'   - Performs best for BOTH orders and revenue')\n    print(f'   - Orders MAPE: {best_orders_mape_val:.2f}%')\n    print(f'   - Revenue MAPE: {best_revenue_mape_val:.2f}%')\n    print(f'\\n   âœ“ RECOMMENDATION: Adopt {best_orders_approach} as the official forecasting method')\nelse:\n    print(f'\\nâš ï¸  SPLIT RESULTS:')\n    print(f'   - Best for Orders:  {best_orders_approach} ({best_orders_mape_val:.2f}% MAPE)')\n    print(f'   - Best for Revenue: {best_revenue_approach} ({best_revenue_mape_val:.2f}% MAPE)')\n    print(f'\\n   âœ“ RECOMMENDATION: Hybrid Approach')\n    print(f'     - Use {best_orders_approach} for operational planning (orders, drivers, capacity)')\n    print(f'     - Use {best_revenue_approach} for financial planning (revenue, budgets)')\n\nprint('\\n\\nðŸ“ˆ WHY SEASONAL NAIVE PERFORMS WELL (if it wins):')\nprint('-' * 80)\nif 'Seasonal_Naive' in [best_orders_approach, best_revenue_approach]:\n    print('   1. CAPTURES SEASONALITY: 2024 monthly pattern repeats in 2025')\n    print('   2. BUSINESS STABILITY: Transport demand follows predictable seasonal cycles')\n    print('   3. SIMPLICITY: Easy to explain and understand for stakeholders')\n    print('   4. ROBUSTNESS: No overfitting to training data noise')\n    print('   5. LIMITED TRAINING DATA: Only 36 months (2022-2024) may be insufficient for complex ML')\n    print('\\n   ðŸ’¡ INSIGHT: Sometimes simple methods outperform complex ML when:')\n    print('      - Strong seasonal patterns exist')\n    print('      - Limited training data available')\n    print('      - Business environment is stable')\n\nprint('\\n\\nðŸ“ OUTPUT FILES CREATED:')\nprint('='*80)\nprint('   1. forecast_validation_all_approaches_summary.csv')\nprint('   2. forecast_validation_all_approaches_orders.html')\nprint('   3. forecast_validation_all_approaches_revenue.html')\nprint('   4. forecast_validation_all_approaches_mape_ranking.html')\nprint('\\n' + '='*80)\nprint('âœ… COMPREHENSIVE MODEL COMPARISON COMPLETE!')\nprint('='*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
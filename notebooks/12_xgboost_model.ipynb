{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Forecasting Model (Model A - Seasonality Focus)\n",
    "\n",
    "This notebook implements XGBoost (Extreme Gradient Boosting) for time series forecasting with engineered temporal features.\n",
    "\n",
    "## XGBoost Advantages\n",
    "- **Non-linear Patterns**: Captures complex relationships\n",
    "- **Feature Importance**: Identifies key drivers\n",
    "- **Robust**: Handles missing values and outliers\n",
    "- **Flexible**: Can incorporate many features\n",
    "\n",
    "## Configuration\n",
    "- **Features**: Temporal (month, quarter, week), lag features [1,3,6,12], rolling statistics\n",
    "- **Hyperparameters**: n_estimators=200, max_depth=6, learning_rate=0.05\n",
    "- **Validation**: Time series split (no data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load company-level time series\n",
    "data_path = Path('../data/processed/monthly_aggregated_full_company.parquet')\n",
    "\n",
    "if not data_path.exists():\n",
    "    data_path = Path('../data/processed/monthly_aggregated_full_company.csv')\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "else:\n",
    "    df = pd.read_parquet(data_path)\n",
    "\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded: {len(df)} months ({df['date'].min()} to {df['date'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Feature Engineering\n",
    "\n",
    "Create temporal features and lag features for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_metrics = [\n",
    "    'total_orders',\n",
    "    'total_km_billed',\n",
    "    'total_km_actual',\n",
    "    'total_tours',\n",
    "    'total_drivers',\n",
    "    'revenue_total',\n",
    "    'external_drivers',\n",
    "    'vehicle_km_cost',      # NEW: KM-based transportation cost\n",
    "    'vehicle_time_cost',    # NEW: Time-based transportation cost\n",
    "    'total_vehicle_cost'    # NEW: Total vehicle operational cost\n",
    "]\n",
    "\n",
    "# Backward compatibility check\n",
    "if 'total_km' in df.columns and 'total_km_billed' not in df.columns:\n",
    "    target_metrics = [m.replace('total_km_billed', 'total_km') if m == 'total_km_billed' else m for m in target_metrics]\n",
    "    target_metrics = [m for m in target_metrics if m != 'total_km_actual']  # Remove if not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Split data: Use all 36 months as training (no validation split needed for baselines)\n# Since we don't have 2025 data yet, we'll use the full historic data as training\n# and demonstrate forecasting forward\n\nprint(\"Creating train/validation split...\")\nprint(\"=\"*80)\n\n# For Prophet models, we'll use last 6 months as validation\nsplit_date = '2024-07-01'\n\ntrain_df = df[df['date'] < split_date].copy()\nval_df = df[df['date'] >= split_date].copy()\n\nprint(f\"\\nTraining data:\")\nprint(f\"  Date range: {train_df['date'].min()} to {train_df['date'].max()}\")\nprint(f\"  Months: {len(train_df)}\")\n\nprint(f\"\\nValidation data:\")\nprint(f\"  Date range: {val_df['date'].min()} to {val_df['date'].max()}\")\nprint(f\"  Months: {len(val_df)}\")\n\nprint(f\"\\n\u2713 Split complete!\")\nprint(f\"  Training: {len(train_df)} months (Jan 2022 - Jun 2024)\")\nprint(f\"  Validation: {len(val_df)} months (Jul 2024 - Dec 2024)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, target_col):\n",
    "    \"\"\"\n",
    "    Create temporal and lag features for XGBoost.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Time series dataframe with 'date' column\n",
    "    target_col : str\n",
    "        Name of the target column to create lag features for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Dataframe with engineered features\n",
    "    \"\"\"\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Temporal features\n",
    "    df_feat['year'] = df_feat['date'].dt.year\n",
    "    df_feat['month'] = df_feat['date'].dt.month\n",
    "    df_feat['quarter'] = df_feat['date'].dt.quarter\n",
    "    df_feat['week'] = df_feat['date'].dt.isocalendar().week\n",
    "    df_feat['day_of_year'] = df_feat['date'].dt.dayofyear\n",
    "    df_feat['weekday'] = df_feat['date'].dt.weekday\n",
    "    \n",
    "    # Lag features (previous months' values)\n",
    "    df_feat[f'lag_1'] = df_feat[target_col].shift(1)\n",
    "    df_feat[f'lag_3'] = df_feat[target_col].shift(3)\n",
    "    df_feat[f'lag_6'] = df_feat[target_col].shift(6)\n",
    "    df_feat[f'lag_12'] = df_feat[target_col].shift(12)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df_feat[f'rolling_mean_3'] = df_feat[target_col].rolling(window=3, min_periods=1).mean()\n",
    "    df_feat[f'rolling_std_3'] = df_feat[target_col].rolling(window=3, min_periods=1).std()\n",
    "    df_feat[f'rolling_mean_6'] = df_feat[target_col].rolling(window=6, min_periods=1).mean()\n",
    "    \n",
    "    # Growth rate features\n",
    "    df_feat[f'growth_rate_1'] = df_feat[target_col].pct_change(1)\n",
    "    df_feat[f'growth_rate_3'] = df_feat[target_col].pct_change(3)\n",
    "    df_feat[f'growth_rate_12'] = df_feat[target_col].pct_change(12)\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "print(\"\u2713 Feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_end = '2024-06-30'\n",
    "val_start = '2024-07-01'\n",
    "val_end = '2024-12-31'\n",
    "\n",
    "print(f\"Data Split:\")\n",
    "print(f\"  Training: up to {train_end}\")\n",
    "print(f\"  Validation: {val_start} to {val_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Train XGBoost Models\n",
    "\n",
    "Train one XGBoost model per target metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    target_col, 'date', 'year_month',\n",
    "    'total_orders', 'total_km_billed', 'total_km_actual', 'total_tours',\n",
    "    'total_drivers', 'external_drivers', 'internal_drivers', 'revenue_total',\n",
    "    'vehicle_km_cost', 'vehicle_time_cost', 'total_vehicle_cost',  # NEW: Cost metrics\n",
    "    'total_km',  # For backward compatibility\n",
    "    'Delivery', 'Leergut', 'Pickup/Multi-leg', 'Retoure/Abholung', 'km_per_order'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Feature Importance Analysis\n",
    "\n",
    "Identify which features contribute most to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for first metric\n",
    "metric = target_metrics[0]\n",
    "model = xgb_models[metric]\n",
    "feature_cols = xgb_feature_cols[metric]\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Features for {metric}:\")\n",
    "print(\"=\"*50)\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "fig = go.Figure([\n",
    "    go.Bar(\n",
    "        y=importance_df.head(15)['feature'],\n",
    "        x=importance_df.head(15)['importance'],\n",
    "        orientation='h'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Top 15 Feature Importances - {metric}\",\n",
    "    xaxis_title=\"Importance\",\n",
    "    yaxis_title=\"Feature\",\n",
    "    height=600,\n",
    "    yaxis={'categoryorder': 'total ascending'}\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save\n",
    "results_dir = Path('../results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "fig.write_html(results_dir / f'xgboost_feature_importance_{metric}.html')\n",
    "print(f\"\\n\u2713 Saved: results/xgboost_feature_importance_{metric}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Generate Forecasts\n",
    "\n",
    "Generate predictions for validation and future periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xgb_forecasts(model, df_feat, feature_cols, target_col, val_start, val_end, horizon=18):\n",
    "    \"\"\"\n",
    "    Generate XGBoost forecasts.\n",
    "    \n",
    "    Note: For true future forecasts, we'd need to implement recursive forecasting\n",
    "    (using predictions as lag features). For now, we'll forecast validation period\n",
    "    where actual lag values are available.\n",
    "    \"\"\"\n",
    "    # Validation period\n",
    "    val_df = df_feat[(df_feat['date'] >= val_start) & (df_feat['date'] <= val_end)].copy()\n",
    "    \n",
    "    if len(val_df) == 0:\n",
    "        print(f\"  \u26a0\ufe0f  No validation data available for {target_col}\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # Get features (handle any NaN)\n",
    "    X_val = val_df[feature_cols]\n",
    "    \n",
    "    # Check for NaN in features\n",
    "    if X_val.isna().any().any():\n",
    "        print(f\"  \u26a0\ufe0f  Warning: NaN values in validation features, filling with mean\")\n",
    "        X_val = X_val.fillna(X_val.mean())\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X_val)\n",
    "    \n",
    "    return predictions, val_df['date'].values\n",
    "\n",
    "# Generate forecasts\n",
    "xgb_forecasts = {}\n",
    "xgb_forecast_dates = {}\n",
    "\n",
    "for metric in target_metrics:\n",
    "    model = xgb_models[metric]\n",
    "    df_feat = xgb_dataframes[metric]\n",
    "    feature_cols = xgb_feature_cols[metric]\n",
    "    \n",
    "    predictions, dates = generate_xgb_forecasts(\n",
    "        model, df_feat, feature_cols, metric, val_start, val_end\n",
    "    )\n",
    "    \n",
    "    xgb_forecasts[metric] = predictions\n",
    "    xgb_forecast_dates[metric] = dates\n",
    "    \n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  Validation forecast: {len(predictions)} months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, model_name, metric_name):\n",
    "    \"\"\"Calculate forecast accuracy metrics.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'metric': metric_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "results = []\n",
    "\n",
    "val_df = df[(df['date'] >= val_start) & (df['date'] <= val_end)]\n",
    "\n",
    "for metric in target_metrics:\n",
    "    if len(xgb_forecasts[metric]) > 0:\n",
    "        y_true = val_df[metric].values\n",
    "        y_pred = xgb_forecasts[metric]\n",
    "        \n",
    "        metrics = calculate_metrics(y_true, y_pred, 'XGBoost', metric)\n",
    "        results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nXGBoost Model Performance (Validation Period):\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Compare with previous models\n",
    "try:\n",
    "    baseline_df = pd.read_csv('../data/processed/baseline_metrics.csv')\n",
    "    prophet_df = pd.read_csv('../data/processed/prophet_metrics.csv')\n",
    "    sarimax_df = pd.read_csv('../data/processed/sarimax_metrics.csv')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Model Comparison (MAPE):\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for metric in target_metrics:\n",
    "        print(f\"\\n{metric}:\")\n",
    "        \n",
    "        if len(results_df[results_df['metric'] == metric]) > 0:\n",
    "            xgb_mape = results_df[results_df['metric'] == metric]['MAPE'].values[0]\n",
    "            prophet_mape = prophet_df[prophet_df['metric'] == metric]['MAPE'].values[0]\n",
    "            sarimax_mape = sarimax_df[sarimax_df['metric'] == metric]['MAPE'].values[0]\n",
    "            baseline_best_mape = baseline_df[baseline_df['metric'] == metric]['MAPE'].min()\n",
    "            \n",
    "            print(f\"  XGBoost: {xgb_mape:.2f}%\")\n",
    "            print(f\"  SARIMAX: {sarimax_mape:.2f}%\")\n",
    "            print(f\"  Prophet: {prophet_mape:.2f}%\")\n",
    "            print(f\"  Best Baseline: {baseline_best_mape:.2f}%\")\n",
    "            \n",
    "            best_model = min([\n",
    "                ('XGBoost', xgb_mape),\n",
    "                ('SARIMAX', sarimax_mape),\n",
    "                ('Prophet', prophet_mape)\n",
    "            ], key=lambda x: x[1])\n",
    "            \n",
    "            print(f\"  \u2192 Best: {best_model[0]} ({best_model[1]:.2f}%)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u26a0\ufe0f  Could not load previous model metrics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecasts\n",
    "train_df = df[df['date'] <= train_end]\n",
    "val_df = df[(df['date'] >= val_start) & (df['date'] <= val_end)]\n",
    "\n",
    "for metric in target_metrics:\n",
    "    if len(xgb_forecasts[metric]) == 0:\n",
    "        continue\n",
    "        \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Historical training data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=train_df['date'],\n",
    "            y=train_df[metric],\n",
    "            mode='lines+markers',\n",
    "            name='Historical (Training)',\n",
    "            line=dict(color='black', width=2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Actual validation values\n",
    "    if len(val_df) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=val_df['date'],\n",
    "                y=val_df[metric],\n",
    "                mode='lines+markers',\n",
    "                name='Actual (Validation)',\n",
    "                line=dict(color='green', width=3)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # XGBoost forecast\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=xgb_forecast_dates[metric],\n",
    "            y=xgb_forecasts[metric],\n",
    "            mode='lines+markers',\n",
    "            name='XGBoost Forecast',\n",
    "            line=dict(color='purple', width=2, dash='dash')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"XGBoost Forecast - {metric.replace('_', ' ').title()}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=metric.replace('_', ' ').title(),\n",
    "        height=600,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(results_dir / f'xgboost_forecast_{metric}.html')\n",
    "    print(f\"\\n\u2713 Saved: results/xgboost_forecast_{metric}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save performance metrics\n",
    "output_dir = Path('../data/processed')\n",
    "results_df.to_csv(output_dir / 'xgboost_metrics.csv', index=False)\n",
    "print(f\"\u2713 Saved metrics: data/processed/xgboost_metrics.csv\")\n",
    "\n",
    "# Save validation forecasts\n",
    "if len(val_df) > 0 and len(results_df) > 0:\n",
    "    forecast_output = pd.DataFrame({\n",
    "        'date': val_df['date'],\n",
    "        'year_month': val_df['year_month'].astype(str) if 'year_month' in val_df.columns else val_df['date'].dt.to_period('M').astype(str)\n",
    "    })\n",
    "    \n",
    "    for metric in target_metrics:\n",
    "        if len(xgb_forecasts[metric]) > 0:\n",
    "            forecast_output[metric] = xgb_forecasts[metric]\n",
    "    \n",
    "    forecast_output.to_csv(output_dir / 'xgboost_forecast_validation.csv', index=False)\n",
    "    print(f\"\u2713 Saved validation forecasts: data/processed/xgboost_forecast_validation.csv\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"XGBOOST MODEL COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nKey Findings:\")\n",
    "for metric in target_metrics:\n",
    "    if len(results_df[results_df['metric'] == metric]) > 0:\n",
    "        mape = results_df[results_df['metric'] == metric]['MAPE'].values[0]\n",
    "        print(f\"  \u2022 {metric}: MAPE = {mape:.2f}%\")\n",
    "print(f\"\\nNext: Run notebook 13 for Weighted Prophet model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
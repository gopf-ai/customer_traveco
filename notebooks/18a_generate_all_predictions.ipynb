{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 18a: Generate All Model Predictions for Validation\n",
    "\n",
    "This notebook consolidates predictions from all available forecasting models to enable comprehensive comparison.\n",
    "\n",
    "**Available Models:**\n",
    "1. **Human Method**: 2024 annual total ÷ 12 (traditional budgeting)\n",
    "2. **Seasonal Naive**: Use 2024 same-month values\n",
    "3. **XGBoost**: Gradient boosting with lag features\n",
    "4. **CatBoost**: Gradient boosting with categorical features\n",
    "5. **LightGBM**: Microsoft's gradient boosting\n",
    "6. **Ensemble (Best Model)**: Select best performer per metric\n",
    "7. **Ensemble (Weighted)**: Weight models by inverse MAPE\n",
    "8. **Ensemble (Hybrid)**: 60% ML + 40% Human\n",
    "\n",
    "**Output:** Single CSV with all predictions for Jan-Sep 2025 (validation period)\n",
    "\n",
    "**Focus Metrics:** `total_orders` and `revenue_total` (key business metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Notebook 18a: Generate All Model Predictions')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load All Available 2025 Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/processed')\n",
    "\n",
    "# Focus on orders and revenue only\n",
    "focus_metrics = ['total_orders', 'revenue_total']\n",
    "\n",
    "# Filter to Jan-Sep 2025 (validation period with actual data)\n",
    "val_start = '2025-01-01'\n",
    "val_end = '2025-09-01'\n",
    "\n",
    "print('Loading 2025 forecasts from all models...')\n",
    "print(f'Validation period: {val_start} to {val_end} (9 months)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Human Method (2024 ÷ 12)\n",
    "df_human = pd.read_csv(data_dir / 'human_method_2025.csv')\n",
    "df_human['date'] = pd.to_datetime(df_human['date'])\n",
    "df_human = df_human[(df_human['date'] >= val_start) & (df_human['date'] <= val_end)].copy()\n",
    "\n",
    "print(f'✓ Human Method: {len(df_human)} months')\n",
    "for metric in focus_metrics:\n",
    "    print(f'  {metric}: {df_human[metric].iloc[0]:,.0f} (constant)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Seasonal Naive\n",
    "df_seasonal = pd.read_csv(data_dir / 'seasonal_naive_2025.csv')\n",
    "df_seasonal['date'] = pd.to_datetime(df_seasonal['date'])\n",
    "df_seasonal = df_seasonal[(df_seasonal['date'] >= val_start) & (df_seasonal['date'] <= val_end)].copy()\n",
    "\n",
    "print(f'\\n✓ Seasonal Naive: {len(df_seasonal)} months')\n",
    "for metric in focus_metrics:\n",
    "    print(f'  {metric}: {df_seasonal[metric].min():,.0f} - {df_seasonal[metric].max():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. XGBoost\n",
    "try:\n",
    "    df_xgboost = pd.read_csv(data_dir / 'xgboost_forecast_2025.csv')\n",
    "    df_xgboost['date'] = pd.to_datetime(df_xgboost['date'])\n",
    "    df_xgboost = df_xgboost[(df_xgboost['date'] >= val_start) & (df_xgboost['date'] <= val_end)].copy()\n",
    "    \n",
    "    print(f'\\n✓ XGBoost: {len(df_xgboost)} months')\n",
    "    for metric in focus_metrics:\n",
    "        if metric in df_xgboost.columns:\n",
    "            print(f'  {metric}: {df_xgboost[metric].min():,.0f} - {df_xgboost[metric].max():,.0f}')\n",
    "except FileNotFoundError:\n",
    "    print('\\n⚠️  XGBoost forecast not found')\n",
    "    df_xgboost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CatBoost\n",
    "df_catboost = pd.read_csv(data_dir / 'catboost_forecast_2025.csv')\n",
    "df_catboost['date'] = pd.to_datetime(df_catboost['date'])\n",
    "df_catboost = df_catboost[(df_catboost['date'] >= val_start) & (df_catboost['date'] <= val_end)].copy()\n",
    "\n",
    "print(f'\\n✓ CatBoost: {len(df_catboost)} months')\n",
    "for metric in focus_metrics:\n",
    "    print(f'  {metric}: {df_catboost[metric].min():,.0f} - {df_catboost[metric].max():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LightGBM\n",
    "df_lightgbm = pd.read_csv(data_dir / 'lightgbm_forecast_2025.csv')\n",
    "df_lightgbm['date'] = pd.to_datetime(df_lightgbm['date'])\n",
    "df_lightgbm = df_lightgbm[(df_lightgbm['date'] >= val_start) & (df_lightgbm['date'] <= val_end)].copy()\n",
    "\n",
    "print(f'\\n✓ LightGBM: {len(df_lightgbm)} months')\n",
    "for metric in focus_metrics:\n",
    "    print(f'  {metric}: {df_lightgbm[metric].min():,.0f} - {df_lightgbm[metric].max():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-8. Ensemble Methods\n",
    "df_ensemble_best = pd.read_csv(data_dir / 'ensemble_best_model_2025.csv')\n",
    "df_ensemble_best['date'] = pd.to_datetime(df_ensemble_best['date'])\n",
    "df_ensemble_best = df_ensemble_best[(df_ensemble_best['date'] >= val_start) & (df_ensemble_best['date'] <= val_end)].copy()\n",
    "\n",
    "df_ensemble_weighted = pd.read_csv(data_dir / 'ensemble_weighted_2025.csv')\n",
    "df_ensemble_weighted['date'] = pd.to_datetime(df_ensemble_weighted['date'])\n",
    "df_ensemble_weighted = df_ensemble_weighted[(df_ensemble_weighted['date'] >= val_start) & (df_ensemble_weighted['date'] <= val_end)].copy()\n",
    "\n",
    "df_ensemble_hybrid = pd.read_csv(data_dir / 'ensemble_hybrid_2025.csv')\n",
    "df_ensemble_hybrid['date'] = pd.to_datetime(df_ensemble_hybrid['date'])\n",
    "df_ensemble_hybrid = df_ensemble_hybrid[(df_ensemble_hybrid['date'] >= val_start) & (df_ensemble_hybrid['date'] <= val_end)].copy()\n",
    "\n",
    "print(f'\\n✓ Ensemble (Best Model): {len(df_ensemble_best)} months')\n",
    "print(f'✓ Ensemble (Weighted): {len(df_ensemble_weighted)} months')\n",
    "print(f'✓ Ensemble (Hybrid 60/40): {len(df_ensemble_hybrid)} months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Consolidate All Predictions\n",
    "\n",
    "Create a single dataframe with all model predictions for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize consolidated dataframe\n",
    "df_all_predictions = pd.DataFrame({\n",
    "    'date': df_human['date']\n",
    "})\n",
    "\n",
    "print('Consolidating predictions...')\n",
    "print('='*80)\n",
    "\n",
    "# Add predictions from each model (focus metrics only)\n",
    "for metric in focus_metrics:\n",
    "    print(f'\\n{metric}:')\n",
    "    \n",
    "    # Human\n",
    "    df_all_predictions[f'{metric}_human'] = df_human[metric].values\n",
    "    print(f'  ✓ Human')\n",
    "    \n",
    "    # Seasonal Naive\n",
    "    df_all_predictions[f'{metric}_seasonal_naive'] = df_seasonal[metric].values\n",
    "    print(f'  ✓ Seasonal Naive')\n",
    "    \n",
    "    # XGBoost (if available)\n",
    "    if df_xgboost is not None and metric in df_xgboost.columns:\n",
    "        df_all_predictions[f'{metric}_xgboost'] = df_xgboost[metric].values\n",
    "        print(f'  ✓ XGBoost')\n",
    "    \n",
    "    # CatBoost\n",
    "    df_all_predictions[f'{metric}_catboost'] = df_catboost[metric].values\n",
    "    print(f'  ✓ CatBoost')\n",
    "    \n",
    "    # LightGBM\n",
    "    df_all_predictions[f'{metric}_lightgbm'] = df_lightgbm[metric].values\n",
    "    print(f'  ✓ LightGBM')\n",
    "    \n",
    "    # Ensembles\n",
    "    df_all_predictions[f'{metric}_ensemble_best'] = df_ensemble_best[metric].values\n",
    "    df_all_predictions[f'{metric}_ensemble_weighted'] = df_ensemble_weighted[metric].values\n",
    "    df_all_predictions[f'{metric}_ensemble_hybrid'] = df_ensemble_hybrid[metric].values\n",
    "    print(f'  ✓ Ensemble (Best Model)')\n",
    "    print(f'  ✓ Ensemble (Weighted)')\n",
    "    print(f'  ✓ Ensemble (Hybrid)')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print(f'✓ Consolidated predictions: {len(df_all_predictions)} months × {len(df_all_predictions.columns)-1} forecasts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Summary Statistics\n",
    "\n",
    "Display summary statistics for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSummary Statistics: All Models')\n",
    "print('='*80)\n",
    "\n",
    "for metric in focus_metrics:\n",
    "    print(f'\\n{metric.upper()}:')\n",
    "    print('-'*80)\n",
    "    \n",
    "    # Get all columns for this metric\n",
    "    metric_cols = [col for col in df_all_predictions.columns if col.startswith(metric)]\n",
    "    \n",
    "    for col in metric_cols:\n",
    "        model_name = col.replace(f'{metric}_', '').replace('_', ' ').title()\n",
    "        values = df_all_predictions[col]\n",
    "        \n",
    "        print(f'{model_name:25s}: {values.mean():>12,.0f} avg, {values.min():>12,.0f} min, {values.max():>12,.0f} max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Variability Check\n",
    "\n",
    "Identify models with flat predictions (sign of overfitting or insufficient training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nModel Variability Check (Coefficient of Variation):')\n",
    "print('='*80)\n",
    "print('Models with CV < 2% may have insufficient monthly variation\\n')\n",
    "\n",
    "for metric in focus_metrics:\n",
    "    print(f'{metric.upper()}:')\n",
    "    \n",
    "    metric_cols = [col for col in df_all_predictions.columns if col.startswith(metric)]\n",
    "    \n",
    "    for col in metric_cols:\n",
    "        model_name = col.replace(f'{metric}_', '').replace('_', ' ').title()\n",
    "        values = df_all_predictions[col]\n",
    "        \n",
    "        # Coefficient of Variation (CV) = std / mean\n",
    "        cv = (values.std() / values.mean()) * 100\n",
    "        \n",
    "        status = '✓' if cv >= 2 else '⚠️ '\n",
    "        print(f'  {status} {model_name:25s}: CV = {cv:5.2f}%')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Save Consolidated Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_path = data_dir / 'all_model_predictions_2025_validation.csv'\n",
    "df_all_predictions.to_csv(output_path, index=False)\n",
    "\n",
    "print(f'✓ Saved: {output_path.name}')\n",
    "print(f'  {len(df_all_predictions)} rows × {len(df_all_predictions.columns)} columns')\n",
    "\n",
    "# Display first few rows\n",
    "print('\\nFirst 3 months (orders):')\n",
    "orders_cols = ['date'] + [col for col in df_all_predictions.columns if col.startswith('total_orders')]\n",
    "display(df_all_predictions[orders_cols].head(3))\n",
    "\n",
    "print('\\nFirst 3 months (revenue):')\n",
    "revenue_cols = ['date'] + [col for col in df_all_predictions.columns if col.startswith('revenue_total')]\n",
    "display(df_all_predictions[revenue_cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Model Availability Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODEL AVAILABILITY SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print('\\nTraditional Methods:')\n",
    "print('  ✓ Human (2024÷12)')\n",
    "print('  ✓ Seasonal Naive')\n",
    "\n",
    "print('\\nMachine Learning Models:')\n",
    "if df_xgboost is not None:\n",
    "    print('  ✓ XGBoost')\n",
    "else:\n",
    "    print('  ✗ XGBoost (not available)')\n",
    "print('  ✓ CatBoost')\n",
    "print('  ✓ LightGBM')\n",
    "\n",
    "print('\\nEnsemble Methods:')\n",
    "print('  ✓ Best Model per Metric')\n",
    "print('  ✓ Weighted (Inverse MAPE)')\n",
    "print('  ✓ Hybrid (60% ML / 40% Human)')\n",
    "\n",
    "# Count total models\n",
    "total_models = len([col for col in df_all_predictions.columns if col.startswith('total_orders_')])\n",
    "print(f'\\nTotal models available: {total_models}')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('READY FOR VALIDATION')\n",
    "print('='*80)\n",
    "print('Next: Run Notebook 18 (updated) to compare all models against actual 2025 data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison and Final Forecasts\n",
    "\n",
    "This notebook compares all forecasting models and generates final production forecasts.\n",
    "\n",
    "## Models Compared\n",
    "1. **Baselines**: Naive, Seasonal Naive, Moving Average (3, 6), Linear Trend\n",
    "2. **Prophet**: Facebook Prophet with Swiss holidays and custom seasonalities\n",
    "3. **SARIMAX**: Seasonal ARIMA (2,1,2) √ó (1,1,1,12)\n",
    "4. **XGBoost**: Gradient boosting with engineered features\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **MAPE** (Mean Absolute Percentage Error) - Primary metric\n",
    "- **MAE** (Mean Absolute Error)\n",
    "- **RMSE** (Root Mean Square Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load All Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded baseline_metrics.csv: 60 records\n",
      "‚úì Loaded prophet_metrics.csv: 10 records\n",
      "‚úì Loaded sarimax_metrics.csv: 10 records\n",
      "‚úì Loaded xgboost_metrics.csv: 10 records\n",
      "\n",
      "Total model evaluations: 90\n",
      "Models: ['Naive' 'Seasonal Naive' 'MA-3' 'MA-6' 'Linear Trend'\n",
      " 'Linear Distribution (Current Method)' 'Prophet' 'SARIMAX' 'XGBoost']\n",
      "Metrics: ['total_orders' 'total_km_billed' 'total_km_actual' 'total_tours'\n",
      " 'total_drivers' 'revenue_total' 'external_drivers' 'vehicle_km_cost'\n",
      " 'vehicle_time_cost' 'total_vehicle_cost']\n"
     ]
    }
   ],
   "source": [
    "# Load performance metrics from all models\n",
    "metrics_dir = Path('../data/processed')\n",
    "\n",
    "model_files = [\n",
    "    ('baseline_metrics.csv', 'Baseline'),\n",
    "    ('prophet_metrics.csv', 'Prophet'),\n",
    "    ('sarimax_metrics.csv', 'SARIMAX'),\n",
    "    ('xgboost_metrics.csv', 'XGBoost')\n",
    "]\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for filename, model_family in model_files:\n",
    "    filepath = metrics_dir / filename\n",
    "    if filepath.exists():\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['model_family'] = model_family\n",
    "        all_metrics.append(df)\n",
    "        print(f\"‚úì Loaded {filename}: {len(df)} records\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Missing {filename}\")\n",
    "\n",
    "# Combine all metrics\n",
    "if len(all_metrics) > 0:\n",
    "    metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    print(f\"\\nTotal model evaluations: {len(metrics_df)}\")\n",
    "    print(f\"Models: {metrics_df['model'].unique()}\")\n",
    "    print(f\"Metrics: {metrics_df['metric'].unique()}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No model metrics found. Run notebooks 09-12 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Model Rankings by MAPE\n",
    "\n",
    "Rank all models for each target metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Rankings by MAPE\n",
      "================================================================================\n",
      "\n",
      "TOTAL_ORDERS:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      XGBoost                   2.50%        3,578        4,633\n",
      "  2.   Seasonal Naive            2.95%        4,190        5,239\n",
      "  3.   Linear Distribution (Current Method)      4.17%        5,985        7,288\n",
      "  4.   Linear Trend              4.23%        6,097        7,791\n",
      "  5.   MA-3                      4.34%        6,242        7,826\n",
      "\n",
      "TOTAL_KM_BILLED:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      XGBoost                   2.64%      232,754      267,945\n",
      "  2.   Seasonal Naive            2.89%      253,156      288,357\n",
      "  3.   Linear Distribution (Current Method)      3.75%      331,774      384,514\n",
      "  4.   Linear Trend              3.80%      338,258      404,331\n",
      "  5.   MA-6                      4.07%      363,157      437,129\n",
      "\n",
      "TOTAL_KM_ACTUAL:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      MA-6                      3.96%    1,004,540    1,179,934\n",
      "  2.   Linear Trend              4.32%    1,090,921    1,278,119\n",
      "  3.   Naive                     4.77%    1,235,137    1,569,350\n",
      "  4.   XGBoost                   5.11%    1,325,800    1,717,864\n",
      "  5.   Linear Distribution (Current Method)      5.30%    1,373,253    1,745,927\n",
      "\n",
      "TOTAL_TOURS:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      MA-3                      3.61%        5,984        7,210\n",
      "  2.   MA-6                      6.43%       10,695       12,646\n",
      "  3.   Linear Trend              7.71%       12,778       14,515\n",
      "  4.   XGBoost                   7.96%       13,071       14,070\n",
      "  5.   Linear Distribution (Current Method)      8.69%       14,358       15,866\n",
      "\n",
      "TOTAL_DRIVERS:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      XGBoost                   2.58%        3,642        4,889\n",
      "  2.   Seasonal Naive            2.85%        3,986        5,160\n",
      "  3.   Linear Distribution (Current Method)      4.09%        5,770        7,022\n",
      "  4.   Linear Trend              4.16%        5,885        7,501\n",
      "  5.   MA-3                      4.23%        5,980        7,458\n",
      "\n",
      "REVENUE_TOTAL:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      XGBoost                   3.29%      435,339      509,221\n",
      "  2.   Seasonal Naive            4.59%      620,177      722,760\n",
      "  3.   MA-3                      5.42%      705,891      838,837\n",
      "  4.   MA-6                      5.48%      721,243      848,862\n",
      "  5.   Linear Trend              5.53%      723,945      858,954\n",
      "\n",
      "EXTERNAL_DRIVERS:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      XGBoost                   2.73%          752          861\n",
      "  2.   MA-3                      4.38%        1,184        1,510\n",
      "  3.   MA-6                      5.63%        1,482        1,961\n",
      "  4.   Linear Trend              6.05%        1,598        2,038\n",
      "  5.   Linear Distribution (Current Method)     10.45%        2,795        3,177\n",
      "\n",
      "VEHICLE_KM_COST:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      MA-6                      3.99%      940,376    1,124,065\n",
      "  2.   Linear Trend              4.59%    1,078,893    1,242,959\n",
      "  3.   Naive                     5.29%    1,271,082    1,622,304\n",
      "  4.   MA-3                      5.40%    1,218,193    1,428,547\n",
      "  5.   Linear Distribution (Current Method)      5.95%    1,427,750    1,782,654\n",
      "\n",
      "VEHICLE_TIME_COST:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      MA-3                      4.10%    1,251,989    1,348,643\n",
      "  2.   MA-6                      4.20%    1,338,908    1,803,354\n",
      "  3.   Linear Trend              4.40%    1,380,086    1,644,072\n",
      "  4.   SARIMAX                   4.90%    1,501,210    1,606,541\n",
      "  5.   Linear Distribution (Current Method)      6.96%    2,190,638    2,562,621\n",
      "\n",
      "TOTAL_VEHICLE_COST:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Model                      MAPE          MAE         RMSE\n",
      "-----------------------------------------------------------------\n",
      "üèÜ      MA-6                      4.11%    2,279,284    2,851,056\n",
      "  2.   Linear Trend              4.47%    2,453,910    2,864,943\n",
      "  3.   MA-3                      4.52%    2,394,730    2,653,616\n",
      "  4.   Naive                     6.39%    3,544,642    4,269,252\n",
      "  5.   Linear Distribution (Current Method)      6.53%    3,618,389    4,330,677\n",
      "\n",
      "================================================================================\n",
      "BEST MODELS BY METRIC:\n",
      "================================================================================\n",
      "  ‚Ä¢ total_orders: XGBoost (MAPE: 2.50%)\n",
      "  ‚Ä¢ total_km_billed: XGBoost (MAPE: 2.64%)\n",
      "  ‚Ä¢ total_km_actual: MA-6 (MAPE: 3.96%)\n",
      "  ‚Ä¢ total_tours: MA-3 (MAPE: 3.61%)\n",
      "  ‚Ä¢ total_drivers: XGBoost (MAPE: 2.58%)\n",
      "  ‚Ä¢ revenue_total: XGBoost (MAPE: 3.29%)\n",
      "  ‚Ä¢ external_drivers: XGBoost (MAPE: 2.73%)\n",
      "  ‚Ä¢ vehicle_km_cost: MA-6 (MAPE: 3.99%)\n",
      "  ‚Ä¢ vehicle_time_cost: MA-3 (MAPE: 4.10%)\n",
      "  ‚Ä¢ total_vehicle_cost: MA-6 (MAPE: 4.11%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Rankings by MAPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_metrics = metrics_df['metric'].unique()\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for target_metric in target_metrics:\n",
    "    print(f\"\\n{target_metric.upper()}:\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Filter for this metric and sort by MAPE\n",
    "    metric_df = metrics_df[metrics_df['metric'] == target_metric].sort_values('MAPE')\n",
    "    \n",
    "    # Display top 5\n",
    "    print(f\"{'Rank':<6} {'Model':<20} {'MAPE':>10} {'MAE':>12} {'RMSE':>12}\")\n",
    "    print(\"-\"*65)\n",
    "    \n",
    "    for i, row in enumerate(metric_df.head(5).itertuples(), 1):\n",
    "        symbol = \"üèÜ\" if i == 1 else f\"  {i}.\"\n",
    "        print(f\"{symbol:<6} {row.model:<20} {row.MAPE:>9.2f}% {row.MAE:>12,.0f} {row.RMSE:>12,.0f}\")\n",
    "    \n",
    "    # Store best model\n",
    "    best = metric_df.iloc[0]\n",
    "    best_models[target_metric] = best['model']\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODELS BY METRIC:\")\n",
    "print(\"=\"*80)\n",
    "for metric, model in best_models.items():\n",
    "    mape = metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == model)]['MAPE'].values[0]\n",
    "    print(f\"  ‚Ä¢ {metric}: {model} (MAPE: {mape:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Visualization - Model Comparison\n",
    "\n",
    "Create comparison charts for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create MAPE comparison chart - Updated for 10 metrics (2 rows √ó 5 cols)\nnum_metrics = len(target_metrics)\nnum_cols = 5\nnum_rows = (num_metrics + num_cols - 1) // num_cols  # Ceiling division\n\nfig = make_subplots(\n    rows=num_rows, cols=num_cols,\n    subplot_titles=[m.replace('_', ' ').title() for m in target_metrics],\n    horizontal_spacing=0.08,\n    vertical_spacing=0.15\n)\n\ncolors = {\n    'Baseline': '#7f7f7f',\n    'Prophet': '#1f77b4',\n    'SARIMAX': '#ff7f0e',\n    'XGBoost': '#2ca02c'\n}\n\nfor idx, target_metric in enumerate(target_metrics):\n    row = (idx // num_cols) + 1\n    col = (idx % num_cols) + 1\n    \n    metric_df = metrics_df[metrics_df['metric'] == target_metric].sort_values('MAPE')\n    \n    fig.add_trace(\n        go.Bar(\n            y=metric_df['model'],\n            x=metric_df['MAPE'],\n            orientation='h',\n            marker=dict(\n                color=[colors.get(mf, '#999999') for mf in metric_df['model_family']]\n            ),\n            showlegend=False,\n            text=metric_df['MAPE'].apply(lambda x: f\"{x:.1f}%\"),\n            textposition='auto'\n        ),\n        row=row, col=col\n    )\n\n# Update axes labels\nfor i in range(1, num_cols + 1):\n    fig.update_xaxes(title_text=\"MAPE (%)\", row=num_rows, col=i)\n\nfig.update_yaxes(title_text=\"Model\", row=1, col=1)\nif num_rows > 1:\n    fig.update_yaxes(title_text=\"Model\", row=2, col=1)\n\nfig.update_layout(\n    title_text=\"Model Performance Comparison - MAPE (Lower is Better)<br><sub>10 Metrics: Operations + Revenue + Costs</sub>\",\n    height=400 * num_rows,  # Adjust height based on number of rows\n    showlegend=False\n)\n\nfig.show()\n\n# Save\nresults_dir = Path('../results')\nresults_dir.mkdir(exist_ok=True)\nfig.write_html(results_dir / 'model_comparison_mape.html')\nprint(f\"‚úì Saved: results/model_comparison_mape.html\")\nprint(f\"  Layout: {num_rows} rows √ó {num_cols} columns = {num_metrics} metrics\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Load Forecast Data for Visualization\n",
    "\n",
    "Compare actual vs predicted values for best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual monthly data\n",
    "df_actual = pd.read_csv(metrics_dir / 'monthly_aggregated_full_company.csv')\n",
    "df_actual['date'] = pd.to_datetime(df_actual['date'])\n",
    "print(f\"‚úì Loaded actual data: {len(df_actual)} months\")\n",
    "print(f\"  Date range: {df_actual['date'].min()} to {df_actual['date'].max()}\")\n",
    "print(f\"  Columns: {list(df_actual.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/val\n",
    "train_end = '2024-06-30'\n",
    "val_start = '2024-07-01'\n",
    "val_end = '2024-12-31'\n",
    "\n",
    "train_df = df_actual[df_actual['date'] <= train_end]\n",
    "val_df = df_actual[(df_actual['date'] >= val_start) & (df_actual['date'] <= val_end)]\n",
    "\n",
    "print(f\"Training: {len(train_df)} months\")\n",
    "print(f\"Validation: {len(val_df)} months\")\n",
    "\n",
    "# Load forecasts from best models\n",
    "forecasts = {}\n",
    "\n",
    "for metric, best_model in best_models.items():\n",
    "    # Determine which file to load based on model name\n",
    "    if 'Prophet' in best_model:\n",
    "        forecast_file = 'prophet_forecast_validation.csv'\n",
    "    elif 'SARIMAX' in best_model:\n",
    "        forecast_file = 'sarimax_forecast_validation.csv'\n",
    "    elif 'XGBoost' in best_model:\n",
    "        forecast_file = 'xgboost_forecast_validation.csv'\n",
    "    else:\n",
    "        # Baseline model\n",
    "        model_name_clean = best_model.lower().replace(' ', '_').replace('-', '')\n",
    "        forecast_file = f'baseline_forecast_{model_name_clean}.csv'\n",
    "    \n",
    "    forecast_path = metrics_dir / forecast_file\n",
    "    \n",
    "    if forecast_path.exists():\n",
    "        df_forecast = pd.read_csv(forecast_path)\n",
    "        forecasts[metric] = {\n",
    "            'model': best_model,\n",
    "            'data': df_forecast\n",
    "        }\n",
    "        print(f\"‚úì Loaded forecast for {metric}: {best_model}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Forecast file not found: {forecast_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Best Model Forecasts Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecast visualization for each metric\n",
    "for metric in target_metrics:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Historical training data\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=train_df['date'],\n",
    "            y=train_df[metric],\n",
    "            mode='lines',\n",
    "            name='Historical (Training)',\n",
    "            line=dict(color='black', width=2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Actual validation values\n",
    "    if len(val_df) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=val_df['date'],\n",
    "                y=val_df[metric],\n",
    "                mode='lines+markers',\n",
    "                name='Actual (Validation)',\n",
    "                line=dict(color='green', width=3),\n",
    "                marker=dict(size=8)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Best model forecast\n",
    "    if metric in forecasts:\n",
    "        forecast_data = forecasts[metric]['data']\n",
    "        model_name = forecasts[metric]['model']\n",
    "        \n",
    "        if 'date' in forecast_data.columns:\n",
    "            forecast_data['date'] = pd.to_datetime(forecast_data['date'])\n",
    "        \n",
    "        if metric in forecast_data.columns:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=forecast_data['date'],\n",
    "                    y=forecast_data[metric],\n",
    "                    mode='lines+markers',\n",
    "                    name=f'{model_name} Forecast',\n",
    "                    line=dict(color='red', width=2, dash='dash'),\n",
    "                    marker=dict(size=8)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Get MAPE for best model\n",
    "    best_model = best_models[metric]\n",
    "    mape = metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == best_model)]['MAPE'].values[0]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Best Model Forecast - {metric.replace('_', ' ').title()}<br>Model: {best_model} (MAPE: {mape:.2f}%)\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=metric.replace('_', ' ').title(),\n",
    "        height=600,\n",
    "        hovermode='x unified',\n",
    "        legend=dict(x=0.01, y=0.99)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Save\n",
    "    fig.write_html(results_dir / f'best_model_forecast_{metric}.html')\n",
    "    print(f\"‚úì Saved: results/best_model_forecast_{metric}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Generate Future Forecasts (Jul 2025 - Dec 2026)\n",
    "\n",
    "Use best models to generate production forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Future Forecasts (Jul 2025 - Dec 2026)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "future_forecasts = {}\n",
    "\n",
    "for metric, best_model in best_models.items():\n",
    "    # Determine which future forecast file to load\n",
    "    if 'Prophet' in best_model:\n",
    "        future_file = 'prophet_forecast_future.csv'\n",
    "    elif 'SARIMAX' in best_model:\n",
    "        future_file = 'sarimax_forecast_future.csv'\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Future forecasts not available for {best_model}\")\n",
    "        continue\n",
    "    \n",
    "    future_path = metrics_dir / future_file\n",
    "    \n",
    "    if future_path.exists():\n",
    "        df_future = pd.read_csv(future_path)\n",
    "        df_future['date'] = pd.to_datetime(df_future['date'])\n",
    "        \n",
    "        # Filter for Jul 2025 - Dec 2026 (18 months)\n",
    "        df_future = df_future[\n",
    "            (df_future['date'] >= '2025-07-01') & \n",
    "            (df_future['date'] <= '2026-12-31')\n",
    "        ]\n",
    "        \n",
    "        future_forecasts[metric] = {\n",
    "            'model': best_model,\n",
    "            'data': df_future\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{metric} ({best_model}):\")\n",
    "        print(f\"  Forecast period: {df_future['date'].min()} to {df_future['date'].max()}\")\n",
    "        print(f\"  Number of months: {len(df_future)}\")\n",
    "        \n",
    "        if metric in df_future.columns:\n",
    "            print(f\"  Average forecast: {df_future[metric].mean():,.0f}\")\n",
    "            print(f\"  Min: {df_future[metric].min():,.0f}, Max: {df_future[metric].max():,.0f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Future forecast file not found: {future_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Save Consolidated Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model comparison summary\n",
    "summary_df = metrics_df.groupby(['metric', 'model']).agg({\n",
    "    'MAPE': 'first',\n",
    "    'MAE': 'first',\n",
    "    'RMSE': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "summary_df = summary_df.sort_values(['metric', 'MAPE'])\n",
    "\n",
    "summary_df.to_csv(metrics_dir / 'model_comparison_summary.csv', index=False)\n",
    "print(f\"‚úì Saved: data/processed/model_comparison_summary.csv\")\n",
    "\n",
    "# Save best models summary\n",
    "best_models_df = pd.DataFrame([\n",
    "    {\n",
    "        'metric': metric,\n",
    "        'best_model': model,\n",
    "        'mape': metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == model)]['MAPE'].values[0],\n",
    "        'mae': metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == model)]['MAE'].values[0],\n",
    "        'rmse': metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == model)]['RMSE'].values[0]\n",
    "    }\n",
    "    for metric, model in best_models.items()\n",
    "])\n",
    "\n",
    "best_models_df.to_csv(metrics_dir / 'best_models_summary.csv', index=False)\n",
    "print(f\"‚úì Saved: data/processed/best_models_summary.csv\")\n",
    "\n",
    "# Consolidate future forecasts if available\n",
    "if len(future_forecasts) > 0:\n",
    "    # Get common dates across all metrics\n",
    "    first_metric = list(future_forecasts.keys())[0]\n",
    "    consolidated = future_forecasts[first_metric]['data'][['date']].copy()\n",
    "    \n",
    "    for metric, forecast_info in future_forecasts.items():\n",
    "        if metric in forecast_info['data'].columns:\n",
    "            consolidated = consolidated.merge(\n",
    "                forecast_info['data'][['date', metric]],\n",
    "                on='date',\n",
    "                how='outer'\n",
    "            )\n",
    "    \n",
    "    consolidated = consolidated.sort_values('date')\n",
    "    consolidated.to_csv(metrics_dir / 'final_forecasts_2025_2026.csv', index=False)\n",
    "    print(f\"‚úì Saved: data/processed/final_forecasts_2025_2026.csv\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MODEL COMPARISON COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFinal Recommendations:\")\n",
    "for metric, model in best_models.items():\n",
    "    mape = metrics_df[(metrics_df['metric'] == metric) & (metrics_df['model'] == model)]['MAPE'].values[0]\n",
    "    print(f\"  ‚Ä¢ {metric}: Use {model} (MAPE: {mape:.2f}%)\")\n",
    "\n",
    "print(f\"\\nAll results saved to:\")\n",
    "print(f\"  ‚Ä¢ data/processed/model_comparison_summary.csv\")\n",
    "print(f\"  ‚Ä¢ data/processed/best_models_summary.csv\")\n",
    "print(f\"  ‚Ä¢ data/processed/final_forecasts_2025_2026.csv\")\n",
    "print(f\"  ‚Ä¢ results/model_comparison_mape.html\")\n",
    "print(f\"  ‚Ä¢ results/best_model_forecast_*.html (one per metric)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}